{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "QBSCZJ7Qc4dg",
   "metadata": {
    "id": "QBSCZJ7Qc4dg"
   },
   "source": [
    "# BAB Dataset: Linear & Nonlinear Models\n",
    "\n",
    "Organized training and simulation for linear, Stribeck, and black-box models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dRLTEDBOc4dh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dRLTEDBOc4dh",
    "outputId": "4ce3ea28-8918-4030-e76e-0e2e85d5576f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint\n",
    "import bab_datasets as nod\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AaWgHyzpc4di",
   "metadata": {
    "id": "AaWgHyzpc4di"
   },
   "source": [
    "## 1) Protocol + Explicit Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J7gOs4S2c4di",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7gOs4S2c4di",
    "outputId": "bf9d55d2-1288-4f8a-ffcd-6a13ff8ffd09"
   },
   "outputs": [],
   "source": [
    "# Fix SSL certificate issue on macOS (Python 3.14)\n",
    "# import ssl\n",
    "# import certifi\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "velMethod = \"central\"\n",
    "PROTOCOL_MODE = \"split_50_50\"  # \"split_50_50\" or \"classic_train_test\"\n",
    "TRAIN_DATASETS_CLASSIC = [\"multisine_05\"]\n",
    "resample_factor = 50\n",
    "\n",
    "# Load all preprocessed datasets once (explicitly reused for train/test protocol)\n",
    "datasets_cache = {}\n",
    "all_datasets = nod.list_experiments()\n",
    "for ds_name in all_datasets:\n",
    "    data_ds = nod.load_experiment(\n",
    "        ds_name,\n",
    "        preprocess=True,\n",
    "        plot=False,\n",
    "        end_idx=None,\n",
    "        resample_factor=resample_factor,\n",
    "        zoom_last_n=200,\n",
    "        y_dot_method=velMethod,\n",
    "    )\n",
    "    u_ds, y_ds, y_ref_ds, y_dot_ds = data_ds\n",
    "    Ts_ds = data_ds.sampling_time\n",
    "    y_sim_ds = np.column_stack([y_ds, y_dot_ds])\n",
    "    datasets_cache[ds_name] = {\n",
    "        \"u\": u_ds,\n",
    "        \"y\": y_ds,\n",
    "        \"y_ref\": y_ref_ds,\n",
    "        \"y_dot\": y_dot_ds,\n",
    "        \"y_sim\": y_sim_ds,\n",
    "        \"Ts\": Ts_ds,\n",
    "        \"N\": len(u_ds),\n",
    "    }\n",
    "\n",
    "# Build explicit train/test index sets per dataset\n",
    "core_datasets = [d for d in all_datasets if (\"multisine\" in d or \"random_steps\" in d)]\n",
    "external_datasets = [d for d in all_datasets if d not in core_datasets]\n",
    "\n",
    "split_map = {}\n",
    "for ds_name in all_datasets:\n",
    "    N = datasets_cache[ds_name][\"N\"]\n",
    "    if PROTOCOL_MODE == \"split_50_50\":\n",
    "        if ds_name in core_datasets:\n",
    "            mid = N // 2\n",
    "            split_map[ds_name] = {\n",
    "                \"train_idx\": np.arange(0, mid, dtype=int),\n",
    "                \"test_idx\": np.arange(mid, N, dtype=int),\n",
    "            }\n",
    "        else:\n",
    "            split_map[ds_name] = {\n",
    "                \"train_idx\": np.array([], dtype=int),\n",
    "                \"test_idx\": np.arange(0, N, dtype=int),\n",
    "            }\n",
    "    elif PROTOCOL_MODE == \"classic_train_test\":\n",
    "        if ds_name in TRAIN_DATASETS_CLASSIC:\n",
    "            split_map[ds_name] = {\n",
    "                \"train_idx\": np.arange(0, N, dtype=int),\n",
    "                \"test_idx\": np.array([], dtype=int),\n",
    "            }\n",
    "        else:\n",
    "            split_map[ds_name] = {\n",
    "                \"train_idx\": np.array([], dtype=int),\n",
    "                \"test_idx\": np.arange(0, N, dtype=int),\n",
    "            }\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown PROTOCOL_MODE: {PROTOCOL_MODE}\")\n",
    "\n",
    "# Build explicit training arrays by concatenating only training partitions\n",
    "train_blocks_u = []\n",
    "train_blocks_y = []\n",
    "train_block_meta = []\n",
    "Ts_values = []\n",
    "for ds_name in all_datasets:\n",
    "    idx = split_map[ds_name][\"train_idx\"]\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    cache = datasets_cache[ds_name]\n",
    "    train_blocks_u.append(cache[\"u\"][idx])\n",
    "    train_blocks_y.append(cache[\"y_sim\"][idx])\n",
    "    train_block_meta.append((ds_name, len(idx)))\n",
    "    Ts_values.append(cache[\"Ts\"])\n",
    "\n",
    "if len(train_blocks_u) == 0:\n",
    "    raise RuntimeError(\"No training samples selected by the current protocol.\")\n",
    "\n",
    "# Check sampling time consistency before concatenation\n",
    "Ts = Ts_values[0]\n",
    "if not np.allclose(Ts_values, Ts, rtol=0, atol=1e-12):\n",
    "    raise RuntimeError(f\"Inconsistent Ts across training datasets: {Ts_values}\")\n",
    "\n",
    "u = np.concatenate(train_blocks_u, axis=0)\n",
    "y_sim = np.concatenate(train_blocks_y, axis=0)\n",
    "y = y_sim[:, 0]\n",
    "y_dot = y_sim[:, 1]\n",
    "y_ref = np.full_like(y, np.nan)\n",
    "t = np.arange(len(u)) * Ts\n",
    "\n",
    "# Segment boundaries in concatenated training vector (to avoid k-step windows crossing dataset boundaries)\n",
    "train_segments = []\n",
    "cursor = 0\n",
    "for ds_name, seg_len in train_block_meta:\n",
    "    train_segments.append((ds_name, cursor, cursor + seg_len))\n",
    "    cursor += seg_len\n",
    "\n",
    "print(f\"Protocol mode: {PROTOCOL_MODE}\")\n",
    "print(f\"Core datasets: {core_datasets}\")\n",
    "print(f\"External datasets (test-only in split_50_50): {external_datasets}\")\n",
    "print(f\"Training datasets/segments: {train_block_meta}\")\n",
    "print(f\"Total training samples: {len(u)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mPzpgzGfKqWp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mPzpgzGfKqWp",
    "outputId": "c6fcd925-aecb-4d0b-822a-df09024dcc76"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting script for core and external datasets.\n",
    "Append this to your existing data-loading code (after datasets_cache, split_map,\n",
    "core_datasets, and external_datasets are defined).\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_dataset_group(ds_names, datasets_cache, split_map, group_title, velMethod):\n",
    "    \"\"\"Plot u, y, y_dot for a list of dataset names, shading train/test regions.\"\"\"\n",
    "    n_ds = len(ds_names)\n",
    "    if n_ds == 0:\n",
    "        print(f\"No datasets in group '{group_title}'.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(n_ds, 3, figsize=(18, 3.5 * n_ds), squeeze=False)\n",
    "    fig.suptitle(f\"{group_title}  (velMethod = '{velMethod}')\", fontsize=14, fontweight=\"bold\", y=1.01)\n",
    "\n",
    "    for row, ds_name in enumerate(ds_names):\n",
    "        cache = datasets_cache[ds_name]\n",
    "        Ts = cache[\"Ts\"]\n",
    "        N = cache[\"N\"]\n",
    "        t = np.arange(N) * Ts\n",
    "\n",
    "        u = cache[\"u\"]\n",
    "        y = cache[\"y\"]\n",
    "        y_dot = cache[\"y_dot\"]\n",
    "\n",
    "        train_idx = split_map[ds_name][\"train_idx\"]\n",
    "        test_idx = split_map[ds_name][\"test_idx\"]\n",
    "\n",
    "        signals = [\n",
    "            (\"u  (input)\", u, \"tab:blue\"),\n",
    "            (\"y  (output)\", y, \"tab:orange\"),\n",
    "            (\"ẏ  (velocity)\", y_dot, \"tab:green\"),\n",
    "        ]\n",
    "\n",
    "        for col, (label, sig, color) in enumerate(signals):\n",
    "            ax = axes[row, col]\n",
    "            ax.plot(t, sig, color=color, linewidth=0.7, alpha=0.85)\n",
    "\n",
    "            # Shade train / test regions\n",
    "            if len(train_idx) > 0:\n",
    "                t_train_start = t[train_idx[0]]\n",
    "                t_train_end = t[train_idx[-1]]\n",
    "                ax.axvspan(t_train_start, t_train_end, alpha=0.08, color=\"blue\", label=\"train\")\n",
    "            if len(test_idx) > 0:\n",
    "                t_test_start = t[test_idx[0]]\n",
    "                t_test_end = t[test_idx[-1]]\n",
    "                ax.axvspan(t_test_start, t_test_end, alpha=0.08, color=\"red\", label=\"test\")\n",
    "\n",
    "            ax.set_xlabel(\"Time [s]\")\n",
    "            ax.set_ylabel(label)\n",
    "            if col == 0:\n",
    "                ax.set_title(ds_name, fontsize=11, fontweight=\"bold\", loc=\"left\")\n",
    "            if row == 0:\n",
    "                ax.legend(fontsize=8, loc=\"upper right\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ── Plot core datasets ──────────────────────────────────────────────\n",
    "plot_dataset_group(core_datasets, datasets_cache, split_map,\n",
    "                   \"Core Datasets (multisine / random_steps)\", velMethod)\n",
    "\n",
    "# ── Plot external datasets ──────────────────────────────────────────\n",
    "plot_dataset_group(external_datasets, datasets_cache, split_map,\n",
    "                   \"External Datasets (test-only)\", velMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z7yomcjCc4di",
   "metadata": {
    "id": "Z7yomcjCc4di"
   },
   "source": [
    "## 2) Tensor Prep (From Explicit Training Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WCfCLQT3c4di",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCfCLQT3c4di",
    "outputId": "af27a1db-8b92-4432-d6fd-0010715cdaa7"
   },
   "outputs": [],
   "source": [
    "t_tensor = torch.tensor(t, dtype=torch.float32).to(device)\n",
    "u_tensor = torch.tensor(u, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "y_tensor = torch.tensor(y_sim, dtype=torch.float32).to(device)\n",
    "\n",
    "# Precompute valid k-step start indices so minibatches never cross concatenated segment boundaries\n",
    "K_STEPS = 20\n",
    "valid_train_start_idx = []\n",
    "for _, s0, s1 in train_segments:\n",
    "    if (s1 - s0) > K_STEPS:\n",
    "        valid_train_start_idx.extend(range(s0, s1 - K_STEPS))\n",
    "valid_train_start_idx = np.asarray(valid_train_start_idx, dtype=int)\n",
    "\n",
    "if len(valid_train_start_idx) == 0:\n",
    "    raise RuntimeError(\"No valid k-step windows found in training split. Decrease K_STEPS or increase train split size.\")\n",
    "\n",
    "print(f\"Tensor shapes -> t: {tuple(t_tensor.shape)}, u: {tuple(u_tensor.shape)}, y: {tuple(y_tensor.shape)}\")\n",
    "print(f\"Valid train starts: {len(valid_train_start_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hSPs6fwlc4di",
   "metadata": {
    "id": "hSPs6fwlc4di"
   },
   "source": [
    "## 3) Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FNeR8PdOc4di",
   "metadata": {
    "id": "FNeR8PdOc4di"
   },
   "outputs": [],
   "source": [
    "class LinearPhysODE(nn.Module):\n",
    "    # J*thdd + R*thd + K*(th+delta) = Tau*V\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_J = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_R = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_K = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "        self.delta = nn.Parameter(torch.tensor(0.0, dtype=torch.float32))\n",
    "        self.log_Tau = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    def get_params(self):\n",
    "        J = torch.exp(self.log_J)\n",
    "        R = torch.exp(self.log_R)\n",
    "        K = torch.exp(self.log_K)\n",
    "        Tau = torch.exp(self.log_Tau)\n",
    "        return J, R, K, self.delta, Tau\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        J, R, K, delta, Tau = self.get_params()\n",
    "        if self.batch_start_times is not None:\n",
    "            t_abs = self.batch_start_times + t\n",
    "        else:\n",
    "            t_abs = t * torch.ones_like(x[:, 0:1])\n",
    "\n",
    "        k_idx = torch.searchsorted(self.t_series, t_abs.reshape(-1), right=True)\n",
    "        k_idx = torch.clamp(k_idx, 1, len(self.t_series) - 1)\n",
    "        t1, t2 = self.t_series[k_idx - 1].unsqueeze(1), self.t_series[k_idx].unsqueeze(1)\n",
    "        u1, u2 = self.u_series[k_idx - 1], self.u_series[k_idx]\n",
    "        denom = (t2 - t1)\n",
    "        denom[denom < 1e-6] = 1.0\n",
    "        alpha = (t_abs - t1) / denom\n",
    "        u_t = u1 + alpha * (u2 - u1)\n",
    "\n",
    "        th, thd = x[:, 0:1], x[:, 1:2]\n",
    "        thdd = (Tau * u_t - R * thd - K * (th + delta)) / J\n",
    "        return torch.cat([thd, thdd], dim=1)\n",
    "\n",
    "\n",
    "class StribeckPhysODE(nn.Module):\n",
    "    # J*thdd + R*thd + K*(th+delta) + F_stribeck = Tau*V\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_J = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_R = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_K = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "        self.delta = nn.Parameter(torch.tensor(0.0, dtype=torch.float32))\n",
    "        self.log_Tau = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "\n",
    "        self.log_Fc = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_Fs = nn.Parameter(torch.tensor(np.log(0.2), dtype=torch.float32))\n",
    "        self.log_vs = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_b = nn.Parameter(torch.tensor(np.log(0.01), dtype=torch.float32))\n",
    "\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    def get_params(self):\n",
    "        J = torch.exp(self.log_J)\n",
    "        R = torch.exp(self.log_R)\n",
    "        K = torch.exp(self.log_K)\n",
    "        Tau = torch.exp(self.log_Tau)\n",
    "        Fc = torch.exp(self.log_Fc)\n",
    "        Fs = torch.exp(self.log_Fs)\n",
    "        vs = torch.exp(self.log_vs)\n",
    "        b = torch.exp(self.log_b)\n",
    "        return J, R, K, self.delta, Tau, Fc, Fs, vs, b\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        J, R, K, delta, Tau, Fc, Fs, vs, b = self.get_params()\n",
    "        if self.batch_start_times is not None:\n",
    "            t_abs = self.batch_start_times + t\n",
    "        else:\n",
    "            t_abs = t * torch.ones_like(x[:, 0:1])\n",
    "\n",
    "        k_idx = torch.searchsorted(self.t_series, t_abs.reshape(-1), right=True)\n",
    "        k_idx = torch.clamp(k_idx, 1, len(self.t_series) - 1)\n",
    "        t1, t2 = self.t_series[k_idx - 1].unsqueeze(1), self.t_series[k_idx].unsqueeze(1)\n",
    "        u1, u2 = self.u_series[k_idx - 1], self.u_series[k_idx]\n",
    "        denom = (t2 - t1)\n",
    "        denom[denom < 1e-6] = 1.0\n",
    "        alpha = (t_abs - t1) / denom\n",
    "        u_t = u1 + alpha * (u2 - u1)\n",
    "\n",
    "        th, thd = x[:, 0:1], x[:, 1:2]\n",
    "        sgn = torch.tanh(thd / 1e-3)\n",
    "        F_str = (Fc + (Fs - Fc) * torch.exp(-(thd / vs) ** 2)) * sgn + b * thd\n",
    "        thdd = (Tau * u_t - R * thd - K * (th + delta) - F_str) / J\n",
    "        return torch.cat([thd, thdd], dim=1)\n",
    "\n",
    "\n",
    "class BlackBoxODE(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim // 2, 2)\n",
    "        )\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        if self.batch_start_times is not None:\n",
    "            t_abs = self.batch_start_times + t\n",
    "        else:\n",
    "            t_abs = t * torch.ones_like(x[:, 0:1])\n",
    "\n",
    "        k_idx = torch.searchsorted(self.t_series, t_abs.reshape(-1), right=True)\n",
    "        k_idx = torch.clamp(k_idx, 1, len(self.t_series) - 1)\n",
    "        t1, t2 = self.t_series[k_idx - 1].unsqueeze(1), self.t_series[k_idx].unsqueeze(1)\n",
    "        u1, u2 = self.u_series[k_idx - 1], self.u_series[k_idx]\n",
    "        denom = (t2 - t1)\n",
    "        denom[denom < 1e-6] = 1.0\n",
    "        alpha = (t_abs - t1) / denom\n",
    "        u_t = u1 + alpha * (u2 - u1)\n",
    "\n",
    "        nn_input = torch.cat([x, u_t], dim=1)\n",
    "        return self.net(nn_input)\n",
    "\n",
    "\n",
    "class HybridJointODE(nn.Module):\n",
    "    # thdd = physics(theta, theta_dot, u) + NN residual\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.log_J = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_R = nn.Parameter(torch.tensor(np.log(0.1), dtype=torch.float32))\n",
    "        self.log_K = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "        self.delta = nn.Parameter(torch.tensor(0.0, dtype=torch.float32))\n",
    "        self.log_Tau = nn.Parameter(torch.tensor(np.log(1.0), dtype=torch.float32))\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    def _interp_u(self, t, x):\n",
    "        if self.batch_start_times is not None:\n",
    "            t_abs = self.batch_start_times + t\n",
    "        else:\n",
    "            t_abs = t * torch.ones_like(x[:, 0:1])\n",
    "\n",
    "        k_idx = torch.searchsorted(self.t_series, t_abs.reshape(-1), right=True)\n",
    "        k_idx = torch.clamp(k_idx, 1, len(self.t_series) - 1)\n",
    "\n",
    "        t1, t2 = self.t_series[k_idx - 1].unsqueeze(1), self.t_series[k_idx].unsqueeze(1)\n",
    "        u1, u2 = self.u_series[k_idx - 1], self.u_series[k_idx]\n",
    "        denom = (t2 - t1)\n",
    "        denom[denom < 1e-6] = 1.0\n",
    "        alpha = (t_abs - t1) / denom\n",
    "        return u1 + alpha * (u2 - u1)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        J = torch.exp(self.log_J)\n",
    "        R = torch.exp(self.log_R)\n",
    "        K = torch.exp(self.log_K)\n",
    "        Tau = torch.exp(self.log_Tau)\n",
    "\n",
    "        u_t = self._interp_u(t, x)\n",
    "        th, thd = x[:, 0:1], x[:, 1:2]\n",
    "\n",
    "        thdd_phys = (Tau * u_t - R * thd - K * (th + self.delta)) / J\n",
    "        thdd_res = self.net(torch.cat([th, thd, u_t], dim=1))\n",
    "        thdd = thdd_phys + thdd_res\n",
    "        return torch.cat([thd, thdd], dim=1)\n",
    "\n",
    "\n",
    "class HybridFrozenPhysODE(nn.Module):\n",
    "    # thdd = frozen physics(theta, theta_dot, u) + NN residual\n",
    "    def __init__(self, phys_model, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        J0, R0, K0, delta0, Tau0 = phys_model.get_params()\n",
    "        self.register_buffer('J0', J0.detach().clone())\n",
    "        self.register_buffer('R0', R0.detach().clone())\n",
    "        self.register_buffer('K0', K0.detach().clone())\n",
    "        self.register_buffer('delta0', delta0.detach().clone())\n",
    "        self.register_buffer('Tau0', Tau0.detach().clone())\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    def _interp_u(self, t, x):\n",
    "        if self.batch_start_times is not None:\n",
    "            t_abs = self.batch_start_times + t\n",
    "        else:\n",
    "            t_abs = t * torch.ones_like(x[:, 0:1])\n",
    "\n",
    "        k_idx = torch.searchsorted(self.t_series, t_abs.reshape(-1), right=True)\n",
    "        k_idx = torch.clamp(k_idx, 1, len(self.t_series) - 1)\n",
    "\n",
    "        t1, t2 = self.t_series[k_idx - 1].unsqueeze(1), self.t_series[k_idx].unsqueeze(1)\n",
    "        u1, u2 = self.u_series[k_idx - 1], self.u_series[k_idx]\n",
    "        denom = (t2 - t1)\n",
    "        denom[denom < 1e-6] = 1.0\n",
    "        alpha = (t_abs - t1) / denom\n",
    "        return u1 + alpha * (u2 - u1)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        u_t = self._interp_u(t, x)\n",
    "        th, thd = x[:, 0:1], x[:, 1:2]\n",
    "\n",
    "        thdd_phys = (self.Tau0 * u_t - self.R0 * thd - self.K0 * (th + self.delta0)) / self.J0\n",
    "        thdd_res = self.net(torch.cat([th, thd, u_t], dim=1))\n",
    "        thdd = thdd_phys + thdd_res\n",
    "        return torch.cat([thd, thdd], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GK3oKE0tc4di",
   "metadata": {
    "id": "GK3oKE0tc4di"
   },
   "source": [
    "## 4) Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1VgJF7zc4dj",
   "metadata": {
    "id": "s1VgJF7zc4dj"
   },
   "outputs": [],
   "source": [
    "def train_model_obs(model, name, epochs=500, lr=0.02, obs_dim=2):\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    model.to(device)\n",
    "    model.u_series = u_tensor\n",
    "    model.t_series = t_tensor\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    BATCH_SIZE = 128\n",
    "    dt_local = (t_tensor[1] - t_tensor[0]).item()\n",
    "    t_eval = torch.arange(0, K_STEPS * dt_local, dt_local, device=device)\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Sample only from valid indices to keep each k-step rollout inside one training segment\n",
    "        start_idx = np.random.choice(valid_train_start_idx, size=BATCH_SIZE, replace=True)\n",
    "        x0 = y_tensor[start_idx]\n",
    "        model.batch_start_times = t_tensor[start_idx].reshape(-1, 1)\n",
    "\n",
    "        pred_state = odeint(model, x0, t_eval, method='rk4')\n",
    "        pred_obs = pred_state[..., :obs_dim]\n",
    "\n",
    "        batch_targets = []\n",
    "        for i in start_idx:\n",
    "            batch_targets.append(y_tensor[i:i + K_STEPS])\n",
    "        y_target = torch.stack(batch_targets, dim=1)  # [T, B, 2]\n",
    "\n",
    "        # Position-only loss (theta), velocity is used only as IC\n",
    "        pred_pos = pred_obs[..., 0:1]\n",
    "        target_pos = y_target[..., 0:1]\n",
    "        loss = torch.mean((pred_pos - target_pos) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Loss: {loss.item():.6f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xnKnsHjkc4dj",
   "metadata": {
    "id": "xnKnsHjkc4dj"
   },
   "source": [
    "## 5) Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goP6chBTc4dj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goP6chBTc4dj",
    "outputId": "8f6c2626-fc6d-4b2d-c736-045166d6caf0"
   },
   "outputs": [],
   "source": [
    "lin_model = LinearPhysODE()\n",
    "lin_model = train_model_obs(lin_model, \"Linear Model\", epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W01DR-c8c4dj",
   "metadata": {
    "id": "W01DR-c8c4dj"
   },
   "source": [
    "## 6) Train Stribeck Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HYw7csmpc4dk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYw7csmpc4dk",
    "outputId": "6dc11984-060a-428a-83b4-14e1aecf3bbc"
   },
   "outputs": [],
   "source": [
    "str_model = StribeckPhysODE()\n",
    "str_model = train_model_obs(str_model, \"Stribeck Model\", epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cGvtnFDSc4dk",
   "metadata": {
    "id": "cGvtnFDSc4dk"
   },
   "source": [
    "## 7) Train Black-box Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RWrXEydUc4dk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWrXEydUc4dk",
    "outputId": "a68d5af6-72a7-4131-d8f9-c86a2f7a3c4c"
   },
   "outputs": [],
   "source": [
    "bb_model = BlackBoxODE(hidden_dim=128)\n",
    "bb_model = train_model_obs(bb_model, \"Black-Box Model\", epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tihC4zKz1xGf",
   "metadata": {
    "id": "tihC4zKz1xGf"
   },
   "source": [
    "## 8) Train Hybrid Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_01cS4zz1xGg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_01cS4zz1xGg",
    "outputId": "f114f694-a072-477f-b1b6-bf9ba209e10c"
   },
   "outputs": [],
   "source": [
    "hjoint_model = HybridJointODE(hidden_dim=128)\n",
    "hjoint_model = train_model_obs(hjoint_model, \"Hybrid-Joint Model\", epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3JacsT191xGg",
   "metadata": {
    "id": "3JacsT191xGg"
   },
   "source": [
    "## 9) Train Hybrid Frozen-Physics Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oOnuwgcG1xGg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOnuwgcG1xGg",
    "outputId": "c7bb6dab-da5b-4dda-86d6-ae4d9fab4e67"
   },
   "outputs": [],
   "source": [
    "hfrozen_model = HybridFrozenPhysODE(lin_model, hidden_dim=128)\n",
    "hfrozen_model = train_model_obs(hfrozen_model, \"Hybrid-Frozen Model\", epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FifqIyH_c4dk",
   "metadata": {
    "id": "FifqIyH_c4dk"
   },
   "source": [
    "## 8) Simulate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bTBL86z8c4dk",
   "metadata": {
    "id": "bTBL86z8c4dk"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    lin_model.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "    pred_lin = odeint(lin_model, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SlJyE_a4c4dk",
   "metadata": {
    "id": "SlJyE_a4c4dk"
   },
   "source": [
    "## 9) Simulate Stribeck Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y4Y21e_Uc4dk",
   "metadata": {
    "id": "y4Y21e_Uc4dk"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    str_model.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "    pred_str = odeint(str_model, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R-lB4PV0c4dk",
   "metadata": {
    "id": "R-lB4PV0c4dk"
   },
   "source": [
    "## 10) Simulate Black-box Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AAM6QQSGc4dk",
   "metadata": {
    "id": "AAM6QQSGc4dk"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    bb_model.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "    pred_bb = odeint(bb_model, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02LH2rRA1xGh",
   "metadata": {
    "id": "02LH2rRA1xGh"
   },
   "source": [
    "## 12) Simulate Hybrid Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14NGJNiV1xGh",
   "metadata": {
    "id": "14NGJNiV1xGh"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hjoint_model.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "    pred_hjoint = odeint(hjoint_model, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dfmjlquq1xGh",
   "metadata": {
    "id": "Dfmjlquq1xGh"
   },
   "source": [
    "## 13) Simulate Hybrid Frozen-Physics Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mzX-DmLf1xGh",
   "metadata": {
    "id": "mzX-DmLf1xGh"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hfrozen_model.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "    pred_hfrozen = odeint(hfrozen_model, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PmcAEK62c4dk",
   "metadata": {
    "id": "PmcAEK62c4dk"
   },
   "source": [
    "## 11) Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nKkF6sjrc4dk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nKkF6sjrc4dk",
    "outputId": "2ada3283-b023-4bb8-8d72-7bee5f915f5c"
   },
   "outputs": [],
   "source": [
    "# Metrics and residuals for all models\n",
    "models = {\n",
    "    \"Linear\": pred_lin,\n",
    "    \"Stribeck\": pred_str,\n",
    "    \"Black-box\": pred_bb,\n",
    "    \"Hybrid-Joint\": pred_hjoint,\n",
    "    \"Hybrid-Frozen\": pred_hfrozen,\n",
    "}\n",
    "colors = {\n",
    "    \"Linear\": \"tab:red\",\n",
    "    \"Stribeck\": \"tab:blue\",\n",
    "    \"Black-box\": \"tab:green\",\n",
    "    \"Hybrid-Joint\": \"tab:orange\",\n",
    "    \"Hybrid-Frozen\": \"tab:purple\",\n",
    "}\n",
    "styles = {\n",
    "    \"Linear\": \"--\",\n",
    "    \"Stribeck\": \"-.\",\n",
    "    \"Black-box\": \":\",\n",
    "    \"Hybrid-Joint\": \"-\",\n",
    "    \"Hybrid-Frozen\": (0, (3, 1, 1, 1)),\n",
    "}\n",
    "\n",
    "residuals = {}\n",
    "metrics = {}\n",
    "for name, pred in models.items():\n",
    "    res_pos = y_sim[:, 0] - pred[:, 0]\n",
    "    res_vel = y_sim[:, 1] - pred[:, 1]\n",
    "    rmse_pos = np.sqrt(np.mean(res_pos**2))\n",
    "    rmse_vel = np.sqrt(np.mean(res_vel**2))\n",
    "    ss_res_pos = np.sum(res_pos**2)\n",
    "    ss_tot_pos = np.sum((y_sim[:, 0] - np.mean(y_sim[:, 0]))**2)\n",
    "    ss_res_vel = np.sum(res_vel**2)\n",
    "    ss_tot_vel = np.sum((y_sim[:, 1] - np.mean(y_sim[:, 1]))**2)\n",
    "    r2_pos = 1 - ss_res_pos / ss_tot_pos if ss_tot_pos > 0 else np.nan\n",
    "    r2_vel = 1 - ss_res_vel / ss_tot_vel if ss_tot_vel > 0 else np.nan\n",
    "    fit_pos = 100 * (1 - np.linalg.norm(res_pos) / np.linalg.norm(y_sim[:, 0] - np.mean(y_sim[:, 0])))\n",
    "    fit_vel = 100 * (1 - np.linalg.norm(res_vel) / np.linalg.norm(y_sim[:, 1] - np.mean(y_sim[:, 1])))\n",
    "    residuals[name] = {\"pos\": res_pos, \"vel\": res_vel}\n",
    "    metrics[name] = {\"rmse_pos\": rmse_pos, \"rmse_vel\": rmse_vel, \"r2_pos\": r2_pos, \"r2_vel\": r2_vel, \"fit_pos\": fit_pos, \"fit_vel\": fit_vel}\n",
    "\n",
    "# Metrics tables\n",
    "print(\"Metrics - Position\")\n",
    "print(\"Model        RMSE      R2        FIT%\")\n",
    "for name in models.keys():\n",
    "    m = metrics[name]\n",
    "    print(f\"{name:<12} {m['rmse_pos']:<9.4f} {m['r2_pos']:<8.4f} {m['fit_pos']:<8.2f}\")\n",
    "\n",
    "print(\"Metrics - Velocity\")\n",
    "print(\"Model        RMSE      R2        FIT%\")\n",
    "for name in models.keys():\n",
    "    m = metrics[name]\n",
    "    print(f\"{name:<12} {m['rmse_vel']:<9.4f} {m['r2_vel']:<8.4f} {m['fit_vel']:<8.2f}\")\n",
    "\n",
    "# Comparison plots (no metrics in titles)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, y_sim[:, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models.items():\n",
    "    plt.plot(t, pred[:, 0], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "plt.ylabel(\"Position\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Position: Measured vs Predicted\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, y_sim[:, 1], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models.items():\n",
    "    plt.plot(t, pred[:, 1], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Velocity: Measured vs Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zooms (position only)\n",
    "win_sec = 5.0\n",
    "win_n = int(win_sec / Ts)\n",
    "starts = [0, max(0, (len(t) - win_n) // 2), max(0, len(t) - win_n)]\n",
    "labels = [\"Start\", \"Middle\", \"End\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, s in enumerate(starts):\n",
    "    e = min(len(t), s + win_n)\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(t[s:e], y_sim[s:e, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "    for name, pred in models.items():\n",
    "        plt.plot(t[s:e], pred[s:e, 0], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "    plt.title(f\"Zoom ({labels[i]})\")\n",
    "    plt.ylabel('Position')\n",
    "    plt.grid(True)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "    if i == 2:\n",
    "        plt.xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals (all models)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "for name in models.keys():\n",
    "    plt.plot(t, residuals[name]['pos'], color=colors[name], linewidth=1.2, label=name)\n",
    "plt.axhline(0, color='gray', linewidth=1)\n",
    "plt.title('Position Residuals')\n",
    "plt.ylabel('Residual')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for name in models.keys():\n",
    "    plt.plot(t, residuals[name]['vel'], color=colors[name], linewidth=1.2, label=name)\n",
    "plt.axhline(0, color='gray', linewidth=1)\n",
    "plt.title('Velocity Residuals')\n",
    "plt.ylabel('Residual')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Raincloud plot (position residuals)\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "labels = list(models.keys())\n",
    "res_list = [residuals[name]['pos'] for name in labels]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (label, res) in enumerate(zip(labels, res_list)):\n",
    "    res = res[np.isfinite(res)]\n",
    "    kde = gaussian_kde(res)\n",
    "    xs = np.linspace(np.min(res), np.max(res), 200)\n",
    "    ys = kde(xs)\n",
    "    ys = ys / ys.max() * 0.3\n",
    "    plt.fill_between(xs, i + ys, i - ys, color=colors[label], alpha=0.3)\n",
    "    q1, q2, q3 = np.percentile(res, [25, 50, 75])\n",
    "    plt.plot([q1, q3], [i, i], color=colors[label], linewidth=6)\n",
    "    plt.plot([q2, q2], [i-0.1, i+0.1], color='k', linewidth=1)\n",
    "    jitter = (np.random.rand(len(res)) - 0.5) * 0.2\n",
    "    plt.scatter(res, i + jitter, s=3, color=colors[label], alpha=0.3)\n",
    "\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.xlabel('Residual (Position)')\n",
    "plt.title('Residual Raincloud Plot (Position)')\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# y vs yhat (position)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([y_sim[:,0].min(), y_sim[:,0].max()], [y_sim[:,0].min(), y_sim[:,0].max()], 'k--', label='Ideal')\n",
    "for name, pred in models.items():\n",
    "    plt.scatter(y_sim[:,0], pred[:,0], s=6, alpha=0.4, color=colors[name], label=name)\n",
    "plt.xlabel('Measured y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('y vs y_hat (Position)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pd87DsxAc4dl",
   "metadata": {
    "id": "Pd87DsxAc4dl"
   },
   "source": [
    "## 12) Diagnostics (Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i-SpYDO1c4dl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i-SpYDO1c4dl",
    "outputId": "84135daf-20c1-4730-8713-ee1143d93787"
   },
   "outputs": [],
   "source": [
    "# Residual ACF (position) for all models\n",
    "N = len(t)\n",
    "max_lag = min(2000, N - 1)\n",
    "conf = 1.96 / np.sqrt(N)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for name in models.keys():\n",
    "    res = residuals[name]['pos'] - np.mean(residuals[name]['pos'])\n",
    "    acf = np.correlate(res, res, mode='full')\n",
    "    acf = acf[N-1:N+max_lag] / acf[N-1]\n",
    "    plt.plot(np.arange(0, max_lag+1), acf, color=colors[name], linewidth=1.2, label=name)\n",
    "\n",
    "plt.axhline(conf, color='red', linestyle='--', linewidth=1)\n",
    "plt.axhline(-conf, color='red', linestyle='--', linewidth=1)\n",
    "plt.title('Residual ACF (Position)')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Spectrum: measured vs predictions (position)\n",
    "freqs = np.fft.rfftfreq(len(t), d=Ts)\n",
    "Y_meas = np.fft.rfft(y_sim[:, 0])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.semilogy(freqs, np.abs(Y_meas), color='k', label='Measured')\n",
    "for name, pred in models.items():\n",
    "    Y_pred = np.fft.rfft(pred[:, 0])\n",
    "    plt.semilogy(freqs, np.abs(Y_pred), color=colors[name], linewidth=1.2, label=name)\n",
    "plt.title('Spectrum (Position)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Spectrum of position residuals for all models\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.semilogy(freqs, np.abs(Y_meas), color='k', label='Measured')\n",
    "for name in models.keys():\n",
    "    # Calculate FFT of position residuals\n",
    "    res_fft = np.fft.rfft(residuals[name]['pos'])\n",
    "    # Plot magnitude spectrum on a semilogy scale\n",
    "    plt.semilogy(freqs, np.abs(res_fft), color=colors[name], linewidth=1.2, label=name)\n",
    "\n",
    "plt.title('Spectrum of Position Residuals')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude of FFT')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-ItiD3gcoLG8",
   "metadata": {
    "id": "-ItiD3gcoLG8"
   },
   "source": [
    "## 13) Load Test Data and run prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-TuAj529oLG8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-TuAj529oLG8",
    "outputId": "7269fe52-3cf4-4f50-bef8-a45fc6dcb90f"
   },
   "outputs": [],
   "source": [
    "# Reuse protocol from training cell\n",
    "print(\"Using PROTOCOL_MODE:\", PROTOCOL_MODE)\n",
    "print(\"Using TRAIN_DATASETS_CLASSIC:\", TRAIN_DATASETS_CLASSIC)\n",
    "\n",
    "# Evaluate all datasets with protocol, print R2 tables, and plot rainclouds:\n",
    "# - rows = models\n",
    "# - columns = train/test\n",
    "# - each subplot y-axis = datasets\n",
    "\n",
    "# =========================\n",
    "# 1) Evaluation config\n",
    "# =========================\n",
    "PROTOCOL_MODE = \"split_50_50\"  # \"split_50_50\" or \"classic_train_test\"\n",
    "TRAIN_DATASETS_CLASSIC = [\"multisine_05\"]\n",
    "\n",
    "model_objects = {\n",
    "    \"Linear\": lin_model,\n",
    "    \"Stribeck\": str_model,\n",
    "    \"Black-box\": bb_model,\n",
    "    \"Hybrid-Joint\": hjoint_model,\n",
    "    \"Hybrid-Frozen\": hfrozen_model,\n",
    "}\n",
    "model_names = list(model_objects.keys())\n",
    "\n",
    "all_datasets = nod.list_experiments()\n",
    "core_datasets = [d for d in all_datasets if (\"multisine\" in d or \"random_steps\" in d)]\n",
    "external_datasets = [d for d in all_datasets if d not in core_datasets]\n",
    "\n",
    "print(f\"PROTOCOL_MODE: {PROTOCOL_MODE}\")\n",
    "print(f\"Core datasets: {core_datasets}\")\n",
    "print(f\"External datasets: {external_datasets}\")\n",
    "\n",
    "eval_store = {}\n",
    "\n",
    "# =========================\n",
    "# 2) Simulate all datasets\n",
    "# =========================\n",
    "for ds_name in all_datasets:\n",
    "    data_ds = nod.load_experiment(\n",
    "        ds_name,\n",
    "        preprocess=True,\n",
    "        plot=False,\n",
    "        end_idx=None,\n",
    "        resample_factor=50,\n",
    "        zoom_last_n=200,\n",
    "        y_dot_method=velMethod,\n",
    "    )\n",
    "\n",
    "    u_ds, y_ds, y_ref_ds, y_dot_ds = data_ds\n",
    "    Ts_ds = data_ds.sampling_time\n",
    "    t_ds = np.arange(len(u_ds)) * Ts_ds\n",
    "    y_sim_ds = np.column_stack([y_ds, y_dot_ds])\n",
    "\n",
    "    n = len(t_ds)\n",
    "    split_i = int(0.5 * n)\n",
    "\n",
    "    if PROTOCOL_MODE == \"split_50_50\":\n",
    "        if ds_name in core_datasets:\n",
    "            train_idx = np.arange(0, split_i)\n",
    "            test_idx = np.arange(split_i, n)\n",
    "        else:\n",
    "            train_idx = None\n",
    "            test_idx = np.arange(0, n)\n",
    "    elif PROTOCOL_MODE == \"classic_train_test\":\n",
    "        if ds_name in TRAIN_DATASETS_CLASSIC:\n",
    "            train_idx = np.arange(0, n)\n",
    "            test_idx = None\n",
    "        else:\n",
    "            train_idx = None\n",
    "            test_idx = np.arange(0, n)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown PROTOCOL_MODE: {PROTOCOL_MODE}\")\n",
    "\n",
    "    t_ds_tensor = torch.tensor(t_ds, dtype=torch.float32).to(device)\n",
    "    u_ds_tensor = torch.tensor(u_ds, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "    y_ds_tensor = torch.tensor(y_sim_ds, dtype=torch.float32).to(device)\n",
    "\n",
    "    preds_ds = {}\n",
    "    with torch.no_grad():\n",
    "        x0_ds = y_ds_tensor[0].unsqueeze(0)\n",
    "        for model_name, model_obj in model_objects.items():\n",
    "            model_obj.u_series = u_ds_tensor\n",
    "            model_obj.t_series = t_ds_tensor\n",
    "            model_obj.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "            pred = odeint(model_obj, x0_ds, t_ds_tensor, method=\"rk4\").squeeze(1).cpu().numpy()\n",
    "            preds_ds[model_name] = pred\n",
    "\n",
    "    metrics_ds = {m: {\"train\": None, \"test\": None} for m in model_names}\n",
    "    residuals_ds = {m: {\"train\": None, \"test\": None} for m in model_names}\n",
    "\n",
    "    for mname, pred in preds_ds.items():\n",
    "        for split_name, idx in [(\"train\", train_idx), (\"test\", test_idx)]:\n",
    "            if idx is None or len(idx) < 2:\n",
    "                continue\n",
    "\n",
    "            y_true = y_sim_ds[idx]\n",
    "            y_hat = pred[idx]\n",
    "            res_pos = y_true[:, 0] - y_hat[:, 0]\n",
    "            res_vel = y_true[:, 1] - y_hat[:, 1]\n",
    "\n",
    "            rmse_pos = np.sqrt(np.mean(res_pos**2))\n",
    "            rmse_vel = np.sqrt(np.mean(res_vel**2))\n",
    "\n",
    "            ss_res_pos = np.sum(res_pos**2)\n",
    "            ss_tot_pos = np.sum((y_true[:, 0] - np.mean(y_true[:, 0]))**2)\n",
    "            ss_res_vel = np.sum(res_vel**2)\n",
    "            ss_tot_vel = np.sum((y_true[:, 1] - np.mean(y_true[:, 1]))**2)\n",
    "\n",
    "            r2_pos = 1 - ss_res_pos / ss_tot_pos if ss_tot_pos > 0 else np.nan\n",
    "            r2_vel = 1 - ss_res_vel / ss_tot_vel if ss_tot_vel > 0 else np.nan\n",
    "\n",
    "            fit_pos = 100 * (1 - np.linalg.norm(res_pos) / np.linalg.norm(y_true[:, 0] - np.mean(y_true[:, 0])))\n",
    "            fit_vel = 100 * (1 - np.linalg.norm(res_vel) / np.linalg.norm(y_true[:, 1] - np.mean(y_true[:, 1])))\n",
    "\n",
    "            residuals_ds[mname][split_name] = {\"pos\": res_pos, \"vel\": res_vel}\n",
    "            metrics_ds[mname][split_name] = {\n",
    "                \"rmse_pos\": rmse_pos,\n",
    "                \"rmse_vel\": rmse_vel,\n",
    "                \"r2_pos\": r2_pos,\n",
    "                \"r2_vel\": r2_vel,\n",
    "                \"fit_pos\": fit_pos,\n",
    "                \"fit_vel\": fit_vel,\n",
    "            }\n",
    "\n",
    "    eval_store[ds_name] = {\n",
    "        \"t\": t_ds,\n",
    "        \"Ts\": Ts_ds,\n",
    "        \"y_sim\": y_sim_ds,\n",
    "        \"preds\": preds_ds,\n",
    "        \"train_idx\": train_idx,\n",
    "        \"test_idx\": test_idx,\n",
    "        \"metrics\": metrics_ds,\n",
    "        \"residuals\": residuals_ds,\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# 3) R2 tables\n",
    "# =========================\n",
    "def print_r2_table(split_name, component):\n",
    "    key = \"r2_pos\" if component == \"pos\" else \"r2_vel\"\n",
    "    print(f\"\\nR2 table ({component}, {split_name})\")\n",
    "    header = \"model\".ljust(14) + \" \" + \" \".join([d[:12].ljust(12) for d in all_datasets])\n",
    "    print(header)\n",
    "    for mname in model_names:\n",
    "        vals = []\n",
    "        for ds in all_datasets:\n",
    "            m = eval_store[ds][\"metrics\"][mname][split_name]\n",
    "            vals.append(np.nan if m is None else m[key])\n",
    "        row = mname.ljust(14) + \" \" + \" \".join(\n",
    "            [(\"nan\" if np.isnan(v) else f\"{v:.4f}\").ljust(12) for v in vals]\n",
    "        )\n",
    "        print(row)\n",
    "\n",
    "print_r2_table(\"train\", \"pos\")\n",
    "print_r2_table(\"test\", \"pos\")\n",
    "print_r2_table(\"train\", \"vel\")\n",
    "print_r2_table(\"test\", \"vel\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AQBt5J2uRj5S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AQBt5J2uRj5S",
    "outputId": "d45a1a02-13f6-4d4b-b01f-e77dfab515c4"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Rainclouds\n",
    "# rows = models, cols = [train, test], y-axis = datasets\n",
    "# x-axis shared and centered at zero for all subplots\n",
    "# =========================\n",
    "splits = [\"train\", \"test\"]\n",
    "n_models = len(model_names)\n",
    "n_datasets = len(all_datasets)\n",
    "\n",
    "# Global symmetric x-limits around zero across all models/datasets/splits\n",
    "all_residuals = []\n",
    "for mname in model_names:\n",
    "    for split_name in splits:\n",
    "        for ds in all_datasets:\n",
    "            rpack = eval_store[ds][\"residuals\"][mname][split_name]\n",
    "            if rpack is None:\n",
    "                continue\n",
    "            res = np.asarray(rpack[\"pos\"])\n",
    "            res = res[np.isfinite(res)]\n",
    "            if len(res) > 0:\n",
    "                all_residuals.append(res)\n",
    "\n",
    "if len(all_residuals) == 0:\n",
    "    raise RuntimeError(\"No residuals found for raincloud plotting.\")\n",
    "\n",
    "res_concat = np.concatenate(all_residuals)\n",
    "x_abs = np.max(np.abs(res_concat))\n",
    "pad = 0.05 * (x_abs + 1e-12)\n",
    "xlim_shared = (-(x_abs + pad), (x_abs + pad))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_models, 2,\n",
    "    figsize=(14, max(3.0 * n_models, 8)),\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "if n_models == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for r, mname in enumerate(model_names):\n",
    "    model_label = mname.replace(\" Dataset\", \"\").replace(\"_Dataset\", \"\")\n",
    "\n",
    "    for c, split_name in enumerate(splits):\n",
    "        ax = axes[r, c]\n",
    "\n",
    "        for i, ds in enumerate(all_datasets):\n",
    "            rpack = eval_store[ds][\"residuals\"][mname][split_name]\n",
    "            if rpack is None:\n",
    "                continue\n",
    "\n",
    "            res = np.asarray(rpack[\"pos\"])\n",
    "            res = res[np.isfinite(res)]\n",
    "            if len(res) < 5:\n",
    "                continue\n",
    "\n",
    "            # cloud\n",
    "            xs = np.linspace(np.min(res), np.max(res), 200)\n",
    "            kde = gaussian_kde(res)\n",
    "            ys = kde(xs)\n",
    "            ys = ys / ys.max() * 0.25\n",
    "            ax.fill_between(xs, i + ys, i - ys, color=\"gray\", alpha=0.25)\n",
    "\n",
    "            # box-like summary\n",
    "            q1, q2, q3 = np.percentile(res, [25, 50, 75])\n",
    "            ax.plot([q1, q3], [i, i], color=\"black\", linewidth=5)\n",
    "            ax.plot([q2, q2], [i - 0.12, i + 0.12], color=\"black\", linewidth=1)\n",
    "\n",
    "            # rain\n",
    "            jitter = (np.random.rand(len(res)) - 0.5) * 0.18\n",
    "            ax.scatter(res, i + jitter, s=2, color=\"gray\", alpha=0.25)\n",
    "\n",
    "        if r == 0:\n",
    "            ax.set_title(f\"Residual Raincloud ({split_name})\")\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(model_label)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        ax.set_xlabel(\"Position residual\")\n",
    "        ax.grid(True, axis=\"x\", alpha=0.35)\n",
    "        ax.axvline(0.0, color=\"k\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "        # show dataset labels on every subplot\n",
    "        ax.set_yticks(range(n_datasets))\n",
    "        ax.set_yticklabels(all_datasets)\n",
    "\n",
    "        # enforce shared symmetric limits\n",
    "        ax.set_xlim(*xlim_shared)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EtZ6x5YboLG8",
   "metadata": {
    "id": "EtZ6x5YboLG8"
   },
   "source": [
    "## 14) Simulate All Models on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v-AsWiP6oLG8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-AsWiP6oLG8",
    "outputId": "475ab443-2674-4d2d-8471-59036bc3d7a0"
   },
   "outputs": [],
   "source": [
    "# Choose which test dataset to plot\n",
    "plot_dataset = \"swept_sine\"  # change this to any dataset in test_datasets\n",
    "\n",
    "if plot_dataset not in eval_store:\n",
    "    raise ValueError(f\"Dataset '{plot_dataset}' not found in eval_store. Available: {list(eval_store.keys())}\")\n",
    "\n",
    "t_test = eval_store[plot_dataset][\"t\"]\n",
    "Ts_test = eval_store[plot_dataset][\"Ts\"]\n",
    "y_sim_test = eval_store[plot_dataset][\"y_sim\"]\n",
    "models_test = eval_store[plot_dataset][\"preds\"]\n",
    "residuals_test = eval_store[plot_dataset][\"residuals\"]\n",
    "metrics_test = eval_store[plot_dataset][\"metrics\"]\n",
    "\n",
    "print(f\"Selected dataset for plots: {plot_dataset}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ZxNS2CkoLG9",
   "metadata": {
    "id": "0ZxNS2CkoLG9"
   },
   "source": [
    "## 15) Test Comparison Plots and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yfGbYZWHG_qE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfGbYZWHG_qE",
    "outputId": "82b6eecb-2803-4834-cd15-0655384b5d9f"
   },
   "outputs": [],
   "source": [
    "# Choose which dataset and split to plot\n",
    "plot_dataset = \"random_steps_01\"  # any key from eval_store\n",
    "plot_split = \"test\"               # \"train\" or \"test\"\n",
    "\n",
    "if plot_dataset not in eval_store:\n",
    "    raise ValueError(f\"Dataset '{plot_dataset}' not found. Available: {list(eval_store.keys())}\")\n",
    "if plot_split not in [\"train\", \"test\"]:\n",
    "    raise ValueError(\"plot_split must be 'train' or 'test'\")\n",
    "\n",
    "idx = eval_store[plot_dataset][f\"{plot_split}_idx\"]\n",
    "if idx is None or len(idx) < 2:\n",
    "    raise ValueError(f\"No '{plot_split}' samples for dataset '{plot_dataset}'\")\n",
    "\n",
    "base = eval_store[plot_dataset]\n",
    "t_all = base[\"t\"]\n",
    "y_all = base[\"y_sim\"]\n",
    "models_all = base[\"preds\"]\n",
    "metrics_all = base[\"metrics\"]\n",
    "residuals_all = base[\"residuals\"]\n",
    "Ts_sel = base[\"Ts\"]\n",
    "\n",
    "t_sel = t_all[idx]\n",
    "y_sel = y_all[idx]\n",
    "models_sel = {name: pred[idx] for name, pred in models_all.items()}\n",
    "residuals_sel = {name: residuals_all[name][plot_split] for name in models_all.keys()}\n",
    "metrics_sel = {name: metrics_all[name][plot_split] for name in models_all.keys()}\n",
    "\n",
    "print(f\"Selected dataset: {plot_dataset} | split: {plot_split} | samples: {len(idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NTmAgKkZoLG9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NTmAgKkZoLG9",
    "outputId": "8f70a5ba-e435-46fa-d5d6-d0f7681d93f5"
   },
   "outputs": [],
   "source": [
    "# Metrics tables for selected dataset/split\n",
    "print(f\"Metrics - Position ({plot_dataset}, {plot_split})\")\n",
    "print(\"Model          RMSE      R2        FIT%\")\n",
    "for name in models_sel.keys():\n",
    "    m = metrics_sel[name]\n",
    "    print(f\"{name:<14} {m['rmse_pos']:<9.4f} {m['r2_pos']:<8.4f} {m['fit_pos']:<8.2f}\")\n",
    "\n",
    "print(f\"\\nMetrics - Velocity ({plot_dataset}, {plot_split})\")\n",
    "print(\"Model          RMSE      R2        FIT%\")\n",
    "for name in models_sel.keys():\n",
    "    m = metrics_sel[name]\n",
    "    print(f\"{name:<14} {m['rmse_vel']:<9.4f} {m['r2_vel']:<8.4f} {m['fit_vel']:<8.2f}\")\n",
    "\n",
    "# Predictions vs measured\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t_sel, y_sel[:, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models_sel.items():\n",
    "    plt.plot(t_sel, pred[:, 0], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "plt.ylabel(\"Position\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(f\"Position: Measured vs Predicted ({plot_dataset}, {plot_split})\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t_sel, y_sel[:, 1], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models_sel.items():\n",
    "    plt.plot(t_sel, pred[:, 1], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(f\"Velocity: Measured vs Predicted ({plot_dataset}, {plot_split})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zooms\n",
    "win_sec = 5.0\n",
    "win_n = int(win_sec / Ts_sel)\n",
    "starts = [0, max(0, (len(t_sel) - win_n) // 2), max(0, len(t_sel) - win_n)]\n",
    "labels = [\"Start\", \"Middle\", \"End\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, s in enumerate(starts):\n",
    "    e = min(len(t_sel), s + win_n)\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(t_sel[s:e], y_sel[s:e, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "    for name, pred in models_sel.items():\n",
    "        plt.plot(t_sel[s:e], pred[s:e, 0], linestyle=styles[name], color=colors[name], linewidth=1.5, label=name)\n",
    "    plt.title(f\"Zoom ({labels[i]}) - {plot_dataset} ({plot_split})\")\n",
    "    plt.ylabel('Position')\n",
    "    plt.grid(True)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "    if i == 2:\n",
    "        plt.xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "for name in models_sel.keys():\n",
    "    plt.plot(t_sel, residuals_sel[name]['pos'], color=colors[name], linewidth=1.2, label=name)\n",
    "plt.axhline(0, color='gray', linewidth=1)\n",
    "plt.title(f'Position Residuals ({plot_dataset}, {plot_split})')\n",
    "plt.ylabel('Residual')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for name in models_sel.keys():\n",
    "    plt.plot(t_sel, residuals_sel[name]['vel'], color=colors[name], linewidth=1.2, label=name)\n",
    "plt.axhline(0, color='gray', linewidth=1)\n",
    "plt.title(f'Velocity Residuals ({plot_dataset}, {plot_split})')\n",
    "plt.ylabel('Residual')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Raincloud (position residuals)\n",
    "from scipy.stats import gaussian_kde\n",
    "labels_sel = list(models_sel.keys())\n",
    "res_list_sel = [residuals_sel[name]['pos'] for name in labels_sel]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (label, res) in enumerate(zip(labels_sel, res_list_sel)):\n",
    "    res = res[np.isfinite(res)]\n",
    "    kde = gaussian_kde(res)\n",
    "    xs = np.linspace(np.min(res), np.max(res), 200)\n",
    "    ys = kde(xs)\n",
    "    ys = ys / ys.max() * 0.3\n",
    "    plt.fill_between(xs, i + ys, i - ys, color=colors[label], alpha=0.3)\n",
    "    q1, q2, q3 = np.percentile(res, [25, 50, 75])\n",
    "    plt.plot([q1, q3], [i, i], color=colors[label], linewidth=6)\n",
    "    plt.plot([q2, q2], [i-0.1, i+0.1], color='k', linewidth=1)\n",
    "    jitter = (np.random.rand(len(res)) - 0.5) * 0.2\n",
    "    plt.scatter(res, i + jitter, s=3, color=colors[label], alpha=0.3)\n",
    "\n",
    "plt.yticks(range(len(labels_sel)), labels_sel)\n",
    "plt.xlabel('Residual (Position)')\n",
    "plt.title(f'Residual Raincloud Plot (Position, {plot_dataset}, {plot_split})')\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# y vs yhat\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([y_sel[:,0].min(), y_sel[:,0].max()], [y_sel[:,0].min(), y_sel[:,0].max()], 'k--', label='Ideal')\n",
    "for name, pred in models_sel.items():\n",
    "    plt.scatter(y_sel[:,0], pred[:,0], s=6, alpha=0.4, color=colors[name], label=name)\n",
    "plt.xlabel('Measured y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title(f'y vs y_hat (Position, {plot_dataset}, {plot_split})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R2N8WHzfoLG9",
   "metadata": {
    "id": "R2N8WHzfoLG9"
   },
   "source": [
    "## 16) Test Diagnostics (ACF and Spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IippcqVzoLG9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IippcqVzoLG9",
    "outputId": "c008a8f4-bc36-424e-d676-2592af01fed6"
   },
   "outputs": [],
   "source": [
    "# ACF (position) for selected dataset/split\n",
    "N_sel = len(t_sel)\n",
    "max_lag_sel = min(2000, N_sel - 1)\n",
    "conf_sel = 1.96 / np.sqrt(N_sel)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for name in models_sel.keys():\n",
    "    res = residuals_sel[name]['pos'] - np.mean(residuals_sel[name]['pos'])\n",
    "    acf = np.correlate(res, res, mode='full')\n",
    "    acf = acf[N_sel-1:N_sel+max_lag_sel] / acf[N_sel-1]\n",
    "    plt.plot(np.arange(0, max_lag_sel + 1), acf, color=colors[name], linewidth=1.2, label=name)\n",
    "\n",
    "plt.axhline(conf_sel, color='red', linestyle='--', linewidth=1)\n",
    "plt.axhline(-conf_sel, color='red', linestyle='--', linewidth=1)\n",
    "plt.title(f'Residual ACF (Position, {plot_dataset}, {plot_split})')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Spectrum: measured vs predictions\n",
    "freqs_sel = np.fft.rfftfreq(len(t_sel), d=Ts_sel)\n",
    "Y_meas_sel = np.fft.rfft(y_sel[:, 0])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.semilogy(freqs_sel, np.abs(Y_meas_sel), color='k', label='Measured')\n",
    "for name, pred in models_sel.items():\n",
    "    Y_pred = np.fft.rfft(pred[:, 0])\n",
    "    plt.semilogy(freqs_sel, np.abs(Y_pred), color=colors[name], linewidth=1.2, label=name)\n",
    "plt.title(f'Spectrum (Position, {plot_dataset}, {plot_split})')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual spectrum\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.semilogy(freqs_sel, np.abs(Y_meas_sel), color='k', label='Measured')\n",
    "for name in models_sel.keys():\n",
    "    res_fft = np.fft.rfft(residuals_sel[name]['pos'])\n",
    "    plt.semilogy(freqs_sel, np.abs(res_fft), color=colors[name], linewidth=1.2, label=name)\n",
    "plt.title(f'Spectrum of Position Residuals ({plot_dataset}, {plot_split})')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude of FFT')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a72d4f",
   "metadata": {
    "id": "f9a72d4f"
   },
   "source": [
    "## Iterate and Plot All Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc5814",
   "metadata": {},
   "source": [
    "# HYCO — Hybrid Cooperative Model\n",
    "\n",
    "**Idea:** Keep a *physical* ODE and a *black-box* neural ODE as two completely separate sub-models.  \n",
    "The composite loss for each mini-batch is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\underbrace{\\mathcal{L}_{\\text{phys}}}_{\\text{physical model vs data}}\n",
    "            + \\lambda_{\\text{bb}} \\, \\underbrace{\\mathcal{L}_{\\text{bb}}}_{\\text{black-box vs data}}\n",
    "            + \\lambda_{\\text{cons}} \\, \\underbrace{\\|\\mathbf{x}_{\\text{phys}} - \\mathbf{x}_{\\text{bb}}\\|^2}_{\\text{consistency}}\n",
    "$$\n",
    "\n",
    "**Alternating optimisation:**\n",
    "- **Odd epochs** → only the *physical* parameters are updated  \n",
    "- **Even epochs** → only the *black-box* NN weights are updated\n",
    "\n",
    "This encourages both sub-models to (a) fit the data individually and (b) agree with each other, without one dominating the gradient flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f17449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# HYCO Model Definition\n",
    "# =====================================================================\n",
    "\n",
    "class HYCOModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Cooperative (HYCO) model.\n",
    "\n",
    "    Wraps a physical ODE and a black-box neural ODE side-by-side.\n",
    "    Both share the same input interpolation machinery but maintain\n",
    "    completely independent parameters.  The forward pass returns\n",
    "    predictions from *both* sub-models so the training loop can\n",
    "    build the composite loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---------- Physical sub-model (Linear ODE) ----------\n",
    "        self.phys = LinearPhysODE()\n",
    "\n",
    "        # ---------- Black-box sub-model ----------\n",
    "        self.bb = BlackBoxODE(hidden_dim=hidden_dim)\n",
    "\n",
    "        # Shared time-series pointers (set before each forward)\n",
    "        self.u_series = None\n",
    "        self.t_series = None\n",
    "        self.batch_start_times = None\n",
    "\n",
    "    # ---- helpers to propagate series pointers ----\n",
    "    def _sync_series(self):\n",
    "        for sub in (self.phys, self.bb):\n",
    "            sub.u_series = self.u_series\n",
    "            sub.t_series = self.t_series\n",
    "            sub.batch_start_times = self.batch_start_times\n",
    "\n",
    "    def phys_params(self):\n",
    "        \"\"\"Iterator over physical-model parameters only.\"\"\"\n",
    "        return self.phys.parameters()\n",
    "\n",
    "    def bb_params(self):\n",
    "        \"\"\"Iterator over black-box-model parameters only.\"\"\"\n",
    "        return self.bb.parameters()\n",
    "\n",
    "\n",
    "def train_hyco(\n",
    "    hyco_model,\n",
    "    epochs=1000,\n",
    "    lr_phys=0.01,\n",
    "    lr_bb=0.01,\n",
    "    lambda_bb=1.0,\n",
    "    lambda_cons=0.5,\n",
    "    batch_size=128,\n",
    "    obs_dim=2,\n",
    "    log_every=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Alternating-epoch training for the HYCO model.\n",
    "\n",
    "    Odd epochs  → update physical parameters only\n",
    "    Even epochs → update black-box NN weights only\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hyco_model : trained model\n",
    "    history    : dict with per-epoch losses\n",
    "    \"\"\"\n",
    "\n",
    "    hyco_model.to(device)\n",
    "    hyco_model.u_series = u_tensor\n",
    "    hyco_model.t_series = t_tensor\n",
    "\n",
    "    opt_phys = optim.Adam(hyco_model.phys_params(), lr=lr_phys)\n",
    "    opt_bb   = optim.Adam(hyco_model.bb_params(),   lr=lr_bb)\n",
    "\n",
    "    dt_local = (t_tensor[1] - t_tensor[0]).item()\n",
    "    t_eval = torch.arange(0, K_STEPS * dt_local, dt_local, device=device)\n",
    "\n",
    "    history = {\n",
    "        \"loss_total\": [],\n",
    "        \"loss_phys\": [],\n",
    "        \"loss_bb\": [],\n",
    "        \"loss_consistency\": [],\n",
    "        \"active_branch\": [],       # \"phys\" or \"bb\"\n",
    "    }\n",
    "\n",
    "    print(f\"--- Training HYCO  (λ_bb={lambda_bb}, λ_cons={lambda_cons}) ---\")\n",
    "    for epoch in range(epochs + 1):\n",
    "\n",
    "        # ---------- choose which optimiser is active ----------\n",
    "        if epoch % 2 == 1:\n",
    "            active_opt = opt_phys\n",
    "            branch = \"phys\"\n",
    "        else:\n",
    "            active_opt = opt_bb\n",
    "            branch = \"bb\"\n",
    "\n",
    "        active_opt.zero_grad()\n",
    "        # also zero the other optimizer so grads don't accumulate\n",
    "        if branch == \"phys\":\n",
    "            opt_bb.zero_grad()\n",
    "        else:\n",
    "            opt_phys.zero_grad()\n",
    "\n",
    "        # ---------- sample mini-batch ----------\n",
    "        start_idx = np.random.choice(valid_train_start_idx,\n",
    "                                     size=batch_size, replace=True)\n",
    "        x0 = y_tensor[start_idx]\n",
    "        hyco_model.batch_start_times = t_tensor[start_idx].reshape(-1, 1)\n",
    "        hyco_model._sync_series()\n",
    "\n",
    "        # ---------- forward both sub-models ----------\n",
    "        pred_phys = odeint(hyco_model.phys, x0, t_eval, method='rk4')  # [T, B, 2]\n",
    "        pred_bb   = odeint(hyco_model.bb,   x0, t_eval, method='rk4')  # [T, B, 2]\n",
    "\n",
    "        # ---------- target ----------\n",
    "        batch_targets = []\n",
    "        for i in start_idx:\n",
    "            batch_targets.append(y_tensor[i:i + K_STEPS])\n",
    "        y_target = torch.stack(batch_targets, dim=1)  # [T, B, 2]\n",
    "\n",
    "        # position-only data losses (consistent with other models)\n",
    "        loss_phys = torch.mean((pred_phys[..., 0:1] - y_target[..., 0:1]) ** 2)\n",
    "        loss_bb   = torch.mean((pred_bb[...,   0:1] - y_target[..., 0:1]) ** 2)\n",
    "\n",
    "        # consistency term: both sub-models should agree on position\n",
    "        loss_cons = torch.mean((pred_phys[..., 0:1] - pred_bb[..., 0:1]) ** 2)\n",
    "\n",
    "        loss_total = loss_phys + lambda_bb * loss_bb + lambda_cons * loss_cons\n",
    "\n",
    "        # ---------- backward + step (only active branch) ----------\n",
    "        loss_total.backward()\n",
    "\n",
    "        # Only step the active optimizer; the other one had its grads zeroed\n",
    "        active_opt.step()\n",
    "\n",
    "        # ---------- bookkeeping ----------\n",
    "        history[\"loss_total\"].append(loss_total.item())\n",
    "        history[\"loss_phys\"].append(loss_phys.item())\n",
    "        history[\"loss_bb\"].append(loss_bb.item())\n",
    "        history[\"loss_consistency\"].append(loss_cons.item())\n",
    "        history[\"active_branch\"].append(branch)\n",
    "\n",
    "        if epoch % log_every == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:>5d} [{branch:>4s}] | \"\n",
    "                f\"L_total={loss_total.item():.6f}  \"\n",
    "                f\"L_phys={loss_phys.item():.6f}  \"\n",
    "                f\"L_bb={loss_bb.item():.6f}  \"\n",
    "                f\"L_cons={loss_cons.item():.6f}\"\n",
    "            )\n",
    "\n",
    "    return hyco_model, history\n",
    "\n",
    "\n",
    "# ---------- instantiate & train ----------\n",
    "hyco_model = HYCOModel(hidden_dim=128)\n",
    "hyco_model, hyco_history = train_hyco(\n",
    "    hyco_model,\n",
    "    epochs=2000,\n",
    "    lr_phys=0.01,\n",
    "    lr_bb=0.01,\n",
    "    lambda_bb=1.0,\n",
    "    lambda_cons=0.5,\n",
    "    batch_size=128,\n",
    "    log_every=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a5d6f",
   "metadata": {},
   "source": [
    "### HYCO Training Diagnostics\n",
    "\n",
    "Loss curves split by component and by active branch, plus convergence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# HYCO Diagnostic Plots — Training Loss Curves\n",
    "# =====================================================================\n",
    "\n",
    "epochs_arr = np.arange(len(hyco_history[\"loss_total\"]))\n",
    "phys_mask = np.array([b == \"phys\" for b in hyco_history[\"active_branch\"]])\n",
    "bb_mask   = ~phys_mask\n",
    "\n",
    "# ── 1) All loss components over epochs ───────────────────────────────\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9), sharex=True)\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.semilogy(epochs_arr, hyco_history[\"loss_total\"], linewidth=0.8, color=\"black\")\n",
    "ax.set_title(\"Total loss  $\\\\mathcal{L}$\")\n",
    "ax.set_ylabel(\"Loss (log)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.semilogy(epochs_arr, hyco_history[\"loss_phys\"], linewidth=0.8, color=\"tab:red\")\n",
    "ax.set_title(\"Physical model loss  $\\\\mathcal{L}_{\\\\mathrm{phys}}$\")\n",
    "ax.set_ylabel(\"Loss (log)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.semilogy(epochs_arr, hyco_history[\"loss_bb\"], linewidth=0.8, color=\"tab:blue\")\n",
    "ax.set_title(\"Black-box loss  $\\\\mathcal{L}_{\\\\mathrm{bb}}$\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss (log)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.semilogy(epochs_arr, hyco_history[\"loss_consistency\"], linewidth=0.8, color=\"tab:green\")\n",
    "ax.set_title(\"Consistency loss  $\\\\|x_{\\\\mathrm{phys}} - x_{\\\\mathrm{bb}}\\\\|^2$\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss (log)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"HYCO — Training Loss Components\", fontsize=14, fontweight=\"bold\", y=1.01)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── 2) Losses split by active branch ────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for ax, key, label, color in [\n",
    "    (axes[0], \"loss_phys\", \"$\\\\mathcal{L}_{\\\\mathrm{phys}}$\", \"tab:red\"),\n",
    "    (axes[1], \"loss_bb\",   \"$\\\\mathcal{L}_{\\\\mathrm{bb}}$\",   \"tab:blue\"),\n",
    "    (axes[2], \"loss_consistency\", \"Consistency\", \"tab:green\"),\n",
    "]:\n",
    "    vals = np.array(hyco_history[key])\n",
    "    ax.semilogy(epochs_arr[phys_mask], vals[phys_mask], '.', markersize=2,\n",
    "                alpha=0.5, color=\"tab:red\",  label=\"phys epoch\")\n",
    "    ax.semilogy(epochs_arr[bb_mask],   vals[bb_mask],   '.', markersize=2,\n",
    "                alpha=0.5, color=\"tab:blue\", label=\"bb epoch\")\n",
    "    ax.set_title(f\"{label} by active branch\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss (log)\")\n",
    "    ax.legend(fontsize=8, markerscale=4)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"HYCO — Loss per Active Branch\", fontsize=13, fontweight=\"bold\", y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── 3) Running average of losses (smoothed) ─────────────────────────\n",
    "def smooth(arr, window=51):\n",
    "    kernel = np.ones(window) / window\n",
    "    return np.convolve(arr, kernel, mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "w = min(51, len(epochs_arr) // 4)\n",
    "for key, label, color in [\n",
    "    (\"loss_total\",       \"Total\",       \"black\"),\n",
    "    (\"loss_phys\",        \"Physical\",    \"tab:red\"),\n",
    "    (\"loss_bb\",          \"Black-box\",   \"tab:blue\"),\n",
    "    (\"loss_consistency\", \"Consistency\", \"tab:green\"),\n",
    "]:\n",
    "    s = smooth(hyco_history[key], window=w)\n",
    "    ax.semilogy(np.arange(len(s)) + w // 2, s, linewidth=1.8, color=color, label=label)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Smoothed loss (log)\")\n",
    "ax.set_title(f\"HYCO — Running-Average Losses (window={w})\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── 4) Ratio  L_bb / L_phys  and  L_cons / L_phys ──────────────────\n",
    "loss_p = np.array(hyco_history[\"loss_phys\"])\n",
    "loss_b = np.array(hyco_history[\"loss_bb\"])\n",
    "loss_c = np.array(hyco_history[\"loss_consistency\"])\n",
    "\n",
    "ratio_bb   = loss_b / (loss_p + 1e-15)\n",
    "ratio_cons = loss_c / (loss_p + 1e-15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "s_bb   = smooth(ratio_bb,   window=w)\n",
    "s_cons = smooth(ratio_cons, window=w)\n",
    "ax.plot(np.arange(len(s_bb))   + w // 2, s_bb,   linewidth=1.5, color=\"tab:blue\",  label=\"$L_{bb}/L_{phys}$\")\n",
    "ax.plot(np.arange(len(s_cons)) + w // 2, s_cons, linewidth=1.5, color=\"tab:green\", label=\"$L_{cons}/L_{phys}$\")\n",
    "ax.axhline(1.0, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss ratio\")\n",
    "ax.set_title(\"HYCO — Loss-Component Ratios (smoothed)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Diagnostic plots complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf620280",
   "metadata": {},
   "source": [
    "### HYCO — Simulate & Compare with Other Models\n",
    "\n",
    "Run both HYCO sub-models on the full training signal, then compare against the previously trained models (Linear, Stribeck, Black-box, Hybrid-Joint, Hybrid-Frozen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ac486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# HYCO — Simulate on training signal & compare with all other models\n",
    "# =====================================================================\n",
    "\n",
    "# --- 1) Simulate HYCO sub-models on the full training time vector ---\n",
    "hyco_model.u_series = u_tensor\n",
    "hyco_model.t_series = t_tensor\n",
    "hyco_model._sync_series()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x0 = y_tensor[0].unsqueeze(0)\n",
    "\n",
    "    hyco_model.phys.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "    hyco_model.bb.batch_start_times   = torch.zeros(1, 1).to(device)\n",
    "\n",
    "    pred_hyco_phys = odeint(hyco_model.phys, x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n",
    "    pred_hyco_bb   = odeint(hyco_model.bb,   x0, t_tensor, method='rk4').squeeze(1).cpu().numpy()\n",
    "\n",
    "# Simple ensemble: average of both sub-model predictions\n",
    "pred_hyco_ens = 0.5 * (pred_hyco_phys + pred_hyco_bb)\n",
    "\n",
    "# --- 2) Build augmented model dict (includes HYCO variants) ---------\n",
    "models_all = {\n",
    "    \"Linear\":        pred_lin,\n",
    "    \"Stribeck\":      pred_str,\n",
    "    \"Black-box\":     pred_bb,\n",
    "    \"Hybrid-Joint\":  pred_hjoint,\n",
    "    \"Hybrid-Frozen\": pred_hfrozen,\n",
    "    \"HYCO-Phys\":     pred_hyco_phys,\n",
    "    \"HYCO-BB\":       pred_hyco_bb,\n",
    "    \"HYCO-Ens\":      pred_hyco_ens,\n",
    "}\n",
    "\n",
    "colors_all = {\n",
    "    \"Linear\":        \"tab:red\",\n",
    "    \"Stribeck\":      \"tab:blue\",\n",
    "    \"Black-box\":     \"tab:green\",\n",
    "    \"Hybrid-Joint\":  \"tab:orange\",\n",
    "    \"Hybrid-Frozen\": \"tab:purple\",\n",
    "    \"HYCO-Phys\":     \"tab:cyan\",\n",
    "    \"HYCO-BB\":       \"darkviolet\",\n",
    "    \"HYCO-Ens\":      \"gold\",\n",
    "}\n",
    "styles_all = {\n",
    "    \"Linear\":        \"--\",\n",
    "    \"Stribeck\":      \"-.\",\n",
    "    \"Black-box\":     \":\",\n",
    "    \"Hybrid-Joint\":  \"-\",\n",
    "    \"Hybrid-Frozen\": (0, (3, 1, 1, 1)),\n",
    "    \"HYCO-Phys\":     (0, (5, 2)),\n",
    "    \"HYCO-BB\":       (0, (1, 1)),\n",
    "    \"HYCO-Ens\":      \"-\",\n",
    "}\n",
    "\n",
    "model_names_all = list(colors_all.keys())\n",
    "\n",
    "# --- 3) Metrics table (training signal) ------------------------------\n",
    "print(\"=\" * 85)\n",
    "print(f\"{'Model':<16} {'RMSE pos':>10} {'R² pos':>10} {'FIT% pos':>10}\"\n",
    "      f\" {'RMSE vel':>10} {'R² vel':>10} {'FIT% vel':>10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "metrics_all_dict = {}\n",
    "for name, pred in models_all.items():\n",
    "    res_pos = y_sim[:, 0] - pred[:, 0]\n",
    "    res_vel = y_sim[:, 1] - pred[:, 1]\n",
    "\n",
    "    rmse_pos = np.sqrt(np.mean(res_pos**2))\n",
    "    rmse_vel = np.sqrt(np.mean(res_vel**2))\n",
    "\n",
    "    ss_res_pos = np.sum(res_pos**2)\n",
    "    ss_tot_pos = np.sum((y_sim[:, 0] - np.mean(y_sim[:, 0]))**2)\n",
    "    ss_res_vel = np.sum(res_vel**2)\n",
    "    ss_tot_vel = np.sum((y_sim[:, 1] - np.mean(y_sim[:, 1]))**2)\n",
    "\n",
    "    r2_pos = 1 - ss_res_pos / ss_tot_pos if ss_tot_pos > 0 else np.nan\n",
    "    r2_vel = 1 - ss_res_vel / ss_tot_vel if ss_tot_vel > 0 else np.nan\n",
    "    fit_pos = 100 * (1 - np.linalg.norm(res_pos) / np.linalg.norm(y_sim[:, 0] - np.mean(y_sim[:, 0])))\n",
    "    fit_vel = 100 * (1 - np.linalg.norm(res_vel) / np.linalg.norm(y_sim[:, 1] - np.mean(y_sim[:, 1])))\n",
    "\n",
    "    metrics_all_dict[name] = dict(\n",
    "        rmse_pos=rmse_pos, r2_pos=r2_pos, fit_pos=fit_pos,\n",
    "        rmse_vel=rmse_vel, r2_vel=r2_vel, fit_vel=fit_vel,\n",
    "        res_pos=res_pos, res_vel=res_vel,\n",
    "    )\n",
    "    print(f\"{name:<16} {rmse_pos:10.4f} {r2_pos:10.4f} {fit_pos:10.2f}\"\n",
    "          f\" {rmse_vel:10.4f} {r2_vel:10.4f} {fit_vel:10.2f}\")\n",
    "print(\"=\" * 85)\n",
    "\n",
    "# --- 4) Position & Velocity comparison plot --------------------------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(t, y_sim[:, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models_all.items():\n",
    "    axes[0].plot(t, pred[:, 0], linestyle=styles_all[name],\n",
    "                 color=colors_all[name], linewidth=1.3, label=name)\n",
    "axes[0].set_ylabel(\"Position\")\n",
    "axes[0].legend(fontsize=7, ncol=3)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_title(\"Position: Measured vs Predicted (all models incl. HYCO)\")\n",
    "\n",
    "axes[1].plot(t, y_sim[:, 1], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "for name, pred in models_all.items():\n",
    "    axes[1].plot(t, pred[:, 1], linestyle=styles_all[name],\n",
    "                 color=colors_all[name], linewidth=1.3, label=name)\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Velocity\")\n",
    "axes[1].legend(fontsize=7, ncol=3)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_title(\"Velocity: Measured vs Predicted (all models incl. HYCO)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 5) Zoom plots (position only) -----------------------------------\n",
    "win_sec = 5.0\n",
    "win_n = int(win_sec / Ts)\n",
    "starts = [0, max(0, (len(t) - win_n) // 2), max(0, len(t) - win_n)]\n",
    "zoom_labels = [\"Start\", \"Middle\", \"End\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 9))\n",
    "for i, s in enumerate(starts):\n",
    "    e = min(len(t), s + win_n)\n",
    "    ax = axes[i]\n",
    "    ax.plot(t[s:e], y_sim[s:e, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "    for name, pred in models_all.items():\n",
    "        ax.plot(t[s:e], pred[s:e, 0], linestyle=styles_all[name],\n",
    "                color=colors_all[name], linewidth=1.3, label=name)\n",
    "    ax.set_title(f\"Zoom ({zoom_labels[i]})\")\n",
    "    ax.set_ylabel(\"Position\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.legend(fontsize=7, ncol=3)\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 6) Residuals (position + velocity) ------------------------------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 7))\n",
    "\n",
    "for name in models_all:\n",
    "    axes[0].plot(t, metrics_all_dict[name][\"res_pos\"],\n",
    "                 color=colors_all[name], linewidth=0.9, label=name)\n",
    "axes[0].axhline(0, color='gray', linewidth=0.8)\n",
    "axes[0].set_title(\"Position Residuals (all models incl. HYCO)\")\n",
    "axes[0].set_ylabel(\"Residual\")\n",
    "axes[0].legend(fontsize=7, ncol=3)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "for name in models_all:\n",
    "    axes[1].plot(t, metrics_all_dict[name][\"res_vel\"],\n",
    "                 color=colors_all[name], linewidth=0.9, label=name)\n",
    "axes[1].axhline(0, color='gray', linewidth=0.8)\n",
    "axes[1].set_title(\"Velocity Residuals (all models incl. HYCO)\")\n",
    "axes[1].set_ylabel(\"Residual\")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].legend(fontsize=7, ncol=3)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 7) Raincloud plot (position residuals) ---------------------------\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, name in enumerate(model_names_all):\n",
    "    res = metrics_all_dict[name][\"res_pos\"]\n",
    "    res = res[np.isfinite(res)]\n",
    "    if len(res) < 5:\n",
    "        continue\n",
    "    kde = gaussian_kde(res)\n",
    "    xs = np.linspace(np.min(res), np.max(res), 200)\n",
    "    ys = kde(xs)\n",
    "    ys = ys / ys.max() * 0.3\n",
    "    ax.fill_between(xs, i + ys, i - ys, color=colors_all[name], alpha=0.3)\n",
    "    q1, q2, q3 = np.percentile(res, [25, 50, 75])\n",
    "    ax.plot([q1, q3], [i, i], color=colors_all[name], linewidth=6)\n",
    "    ax.plot([q2, q2], [i - 0.1, i + 0.1], color='k', linewidth=1)\n",
    "    jitter = (np.random.rand(len(res)) - 0.5) * 0.2\n",
    "    ax.scatter(res, i + jitter, s=2, color=colors_all[name], alpha=0.25)\n",
    "\n",
    "ax.set_yticks(range(len(model_names_all)))\n",
    "ax.set_yticklabels(model_names_all)\n",
    "ax.set_xlabel(\"Residual (Position)\")\n",
    "ax.set_title(\"Residual Raincloud — Position (all models incl. HYCO)\")\n",
    "ax.axvline(0, color='gray', linewidth=0.8, alpha=0.5)\n",
    "ax.grid(True, axis='x', alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 8) y vs ŷ scatter (position) ------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ymin, ymax = y_sim[:, 0].min(), y_sim[:, 0].max()\n",
    "ax.plot([ymin, ymax], [ymin, ymax], 'k--', linewidth=1, label='Ideal')\n",
    "for name, pred in models_all.items():\n",
    "    ax.scatter(y_sim[:, 0], pred[:, 0], s=4, alpha=0.35,\n",
    "               color=colors_all[name], label=name)\n",
    "ax.set_xlabel(\"Measured y\")\n",
    "ax.set_ylabel(\"Predicted y\")\n",
    "ax.set_title(\"y vs ŷ — Position (all models incl. HYCO)\")\n",
    "ax.legend(fontsize=7, markerscale=3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 9) HYCO-specific: Phys vs BB agreement plot ---------------------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 7))\n",
    "\n",
    "axes[0].plot(t, y_sim[:, 0], 'k-', alpha=0.5, linewidth=2, label='Measured')\n",
    "axes[0].plot(t, pred_hyco_phys[:, 0], color='tab:cyan', linewidth=1.3, label='HYCO-Phys')\n",
    "axes[0].plot(t, pred_hyco_bb[:, 0],   color='darkviolet', linewidth=1.3, label='HYCO-BB')\n",
    "axes[0].plot(t, pred_hyco_ens[:, 0],  color='gold', linewidth=1.5, label='HYCO-Ens')\n",
    "axes[0].fill_between(t,\n",
    "                     np.minimum(pred_hyco_phys[:, 0], pred_hyco_bb[:, 0]),\n",
    "                     np.maximum(pred_hyco_phys[:, 0], pred_hyco_bb[:, 0]),\n",
    "                     alpha=0.15, color='gray', label='Phys–BB envelope')\n",
    "axes[0].set_ylabel(\"Position\")\n",
    "axes[0].set_title(\"HYCO Sub-Model Agreement — Position\")\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "diff = pred_hyco_phys[:, 0] - pred_hyco_bb[:, 0]\n",
    "axes[1].plot(t, diff, color='tab:olive', linewidth=0.9)\n",
    "axes[1].axhline(0, color='gray', linewidth=0.8)\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Phys − BB\")\n",
    "axes[1].set_title(\"HYCO Position Disagreement (Phys − BB)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 10) ACF of HYCO-Ens position residuals vs others ----------------\n",
    "N_acf = len(t)\n",
    "max_lag_acf = min(2000, N_acf - 1)\n",
    "conf_acf = 1.96 / np.sqrt(N_acf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for name in models_all:\n",
    "    res = metrics_all_dict[name][\"res_pos\"]\n",
    "    res = res - np.mean(res)\n",
    "    acf = np.correlate(res, res, mode='full')\n",
    "    acf = acf[N_acf - 1 : N_acf + max_lag_acf] / acf[N_acf - 1]\n",
    "    ax.plot(np.arange(max_lag_acf + 1), acf, color=colors_all[name],\n",
    "            linewidth=1.0, label=name)\n",
    "ax.axhline( conf_acf, color='red', linestyle='--', linewidth=0.8)\n",
    "ax.axhline(-conf_acf, color='red', linestyle='--', linewidth=0.8)\n",
    "ax.set_title(\"Residual ACF — Position (all models incl. HYCO)\")\n",
    "ax.set_xlabel(\"Lag\")\n",
    "ax.set_ylabel(\"Autocorrelation\")\n",
    "ax.legend(fontsize=7, ncol=3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 11) Spectrum of position residuals ──────────────────────────────\n",
    "freqs_all = np.fft.rfftfreq(len(t), d=Ts)\n",
    "Y_meas_fft = np.fft.rfft(y_sim[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.semilogy(freqs_all, np.abs(Y_meas_fft), color='k', linewidth=1.2, label='Measured')\n",
    "for name in models_all:\n",
    "    res_fft = np.fft.rfft(metrics_all_dict[name][\"res_pos\"])\n",
    "    ax.semilogy(freqs_all, np.abs(res_fft), color=colors_all[name],\n",
    "                linewidth=0.9, label=name)\n",
    "ax.set_title(\"Spectrum of Position Residuals (all models incl. HYCO)\")\n",
    "ax.set_xlabel(\"Frequency (Hz)\")\n",
    "ax.set_ylabel(\"Magnitude\")\n",
    "ax.legend(fontsize=7, ncol=3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"HYCO comparison on training signal complete.\\n\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# PER-DATASET COMPARISON (all models including HYCO)\n",
    "# =====================================================================\n",
    "\n",
    "# Augment eval_store with HYCO predictions for each dataset\n",
    "hyco_model.eval()\n",
    "for ds_name in all_datasets:\n",
    "    base = eval_store[ds_name]\n",
    "    t_ds = base[\"t\"]\n",
    "    Ts_ds = base[\"Ts\"]\n",
    "    y_sim_ds = base[\"y_sim\"]\n",
    "\n",
    "    t_ds_tensor = torch.tensor(t_ds, dtype=torch.float32).to(device)\n",
    "    u_ds_arr = datasets_cache[ds_name][\"u\"]\n",
    "    u_ds_tensor = torch.tensor(u_ds_arr, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "    y_ds_tensor = torch.tensor(y_sim_ds, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Simulate HYCO sub-models on this dataset\n",
    "    with torch.no_grad():\n",
    "        x0_ds = y_ds_tensor[0].unsqueeze(0)\n",
    "\n",
    "        hyco_model.phys.u_series = u_ds_tensor\n",
    "        hyco_model.phys.t_series = t_ds_tensor\n",
    "        hyco_model.phys.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "        pred_hp = odeint(hyco_model.phys, x0_ds, t_ds_tensor, method=\"rk4\").squeeze(1).cpu().numpy()\n",
    "\n",
    "        hyco_model.bb.u_series = u_ds_tensor\n",
    "        hyco_model.bb.t_series = t_ds_tensor\n",
    "        hyco_model.bb.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "        pred_hb = odeint(hyco_model.bb, x0_ds, t_ds_tensor, method=\"rk4\").squeeze(1).cpu().numpy()\n",
    "\n",
    "    pred_he = 0.5 * (pred_hp + pred_hb)\n",
    "\n",
    "    # Add HYCO predictions to eval_store\n",
    "    base[\"preds\"][\"HYCO-Phys\"] = pred_hp\n",
    "    base[\"preds\"][\"HYCO-BB\"]   = pred_hb\n",
    "    base[\"preds\"][\"HYCO-Ens\"]  = pred_he\n",
    "\n",
    "    # Compute HYCO metrics and residuals per split\n",
    "    for hyco_name, hyco_pred in [(\"HYCO-Phys\", pred_hp), (\"HYCO-BB\", pred_hb), (\"HYCO-Ens\", pred_he)]:\n",
    "        base[\"metrics\"][hyco_name] = {\"train\": None, \"test\": None}\n",
    "        base[\"residuals\"][hyco_name] = {\"train\": None, \"test\": None}\n",
    "\n",
    "        for split_name in [\"train\", \"test\"]:\n",
    "            idx = base[f\"{split_name}_idx\"]\n",
    "            if idx is None or len(idx) < 2:\n",
    "                continue\n",
    "\n",
    "            y_true = y_sim_ds[idx]\n",
    "            y_hat = hyco_pred[idx]\n",
    "            res_pos = y_true[:, 0] - y_hat[:, 0]\n",
    "            res_vel = y_true[:, 1] - y_hat[:, 1]\n",
    "\n",
    "            rmse_pos = np.sqrt(np.mean(res_pos**2))\n",
    "            rmse_vel = np.sqrt(np.mean(res_vel**2))\n",
    "\n",
    "            ss_res_pos = np.sum(res_pos**2)\n",
    "            ss_tot_pos = np.sum((y_true[:, 0] - np.mean(y_true[:, 0]))**2)\n",
    "            ss_res_vel = np.sum(res_vel**2)\n",
    "            ss_tot_vel = np.sum((y_true[:, 1] - np.mean(y_true[:, 1]))**2)\n",
    "\n",
    "            r2_pos = 1 - ss_res_pos / ss_tot_pos if ss_tot_pos > 0 else np.nan\n",
    "            r2_vel = 1 - ss_res_vel / ss_tot_vel if ss_tot_vel > 0 else np.nan\n",
    "\n",
    "            fit_pos = 100 * (1 - np.linalg.norm(res_pos) / np.linalg.norm(y_true[:, 0] - np.mean(y_true[:, 0])))\n",
    "            fit_vel = 100 * (1 - np.linalg.norm(res_vel) / np.linalg.norm(y_true[:, 1] - np.mean(y_true[:, 1])))\n",
    "\n",
    "            base[\"residuals\"][hyco_name][split_name] = {\"pos\": res_pos, \"vel\": res_vel}\n",
    "            base[\"metrics\"][hyco_name][split_name] = {\n",
    "                \"rmse_pos\": rmse_pos, \"rmse_vel\": rmse_vel,\n",
    "                \"r2_pos\": r2_pos, \"r2_vel\": r2_vel,\n",
    "                \"fit_pos\": fit_pos, \"fit_vel\": fit_vel,\n",
    "            }\n",
    "\n",
    "print(\"eval_store augmented with HYCO predictions for all datasets.\\n\")\n",
    "\n",
    "# --- Per-dataset plotting loop ----------------------------------------\n",
    "for plot_dataset_name in all_datasets:\n",
    "    for plot_split in splits:\n",
    "        base = eval_store[plot_dataset_name]\n",
    "        idx = base[f\"{plot_split}_idx\"]\n",
    "        if idx is None or len(idx) < 2:\n",
    "            continue\n",
    "\n",
    "        t_all = base[\"t\"]\n",
    "        y_all = base[\"y_sim\"]\n",
    "        preds_all = base[\"preds\"]\n",
    "        metrics_ds = base[\"metrics\"]\n",
    "        residuals_ds = base[\"residuals\"]\n",
    "        Ts_sel = base[\"Ts\"]\n",
    "\n",
    "        t_sel = t_all[idx]\n",
    "        y_sel = y_all[idx]\n",
    "        models_sel = {name: pred[idx] for name, pred in preds_all.items()}\n",
    "        residuals_sel = {name: residuals_ds[name][plot_split] for name in preds_all.keys()}\n",
    "        metrics_sel = {name: metrics_ds[name][plot_split] for name in preds_all.keys()}\n",
    "\n",
    "        print(f\"\\n{'=' * 85}\")\n",
    "        print(f\"  Dataset: {plot_dataset_name} | Split: {plot_split} | Samples: {len(idx)}\")\n",
    "        print(f\"{'=' * 85}\")\n",
    "\n",
    "        # --- Metrics tables ---\n",
    "        print(f\"\\nMetrics — Position ({plot_dataset_name}, {plot_split})\")\n",
    "        print(f\"{'Model':<16} {'RMSE':>10} {'R²':>10} {'FIT%':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        for name in model_names_all:\n",
    "            m = metrics_sel.get(name)\n",
    "            if m is None:\n",
    "                continue\n",
    "            print(f\"{name:<16} {m['rmse_pos']:10.4f} {m['r2_pos']:10.4f} {m['fit_pos']:10.2f}\")\n",
    "\n",
    "        print(f\"\\nMetrics — Velocity ({plot_dataset_name}, {plot_split})\")\n",
    "        print(f\"{'Model':<16} {'RMSE':>10} {'R²':>10} {'FIT%':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        for name in model_names_all:\n",
    "            m = metrics_sel.get(name)\n",
    "            if m is None:\n",
    "                continue\n",
    "            print(f\"{name:<16} {m['rmse_vel']:10.4f} {m['r2_vel']:10.4f} {m['fit_vel']:10.2f}\")\n",
    "\n",
    "        # --- (A) Measured vs Predicted: position & velocity ---\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "        axes[0].plot(t_sel, y_sel[:, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "        for name, pred in models_sel.items():\n",
    "            axes[0].plot(t_sel, pred[:, 0], linestyle=styles_all[name],\n",
    "                         color=colors_all[name], linewidth=1.3, label=name)\n",
    "        axes[0].set_ylabel(\"Position\")\n",
    "        axes[0].legend(fontsize=7, ncol=3)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].set_title(f\"Position: Measured vs Predicted ({plot_dataset_name}, {plot_split})\")\n",
    "\n",
    "        axes[1].plot(t_sel, y_sel[:, 1], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "        for name, pred in models_sel.items():\n",
    "            axes[1].plot(t_sel, pred[:, 1], linestyle=styles_all[name],\n",
    "                         color=colors_all[name], linewidth=1.3, label=name)\n",
    "        axes[1].set_xlabel(\"Time (s)\")\n",
    "        axes[1].set_ylabel(\"Velocity\")\n",
    "        axes[1].legend(fontsize=7, ncol=3)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        axes[1].set_title(f\"Velocity: Measured vs Predicted ({plot_dataset_name}, {plot_split})\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- (B) Zoom plots (position) ---\n",
    "        win_sec_ds = 5.0\n",
    "        win_n_ds = int(win_sec_ds / Ts_sel)\n",
    "        starts_ds = [0, max(0, (len(t_sel) - win_n_ds) // 2), max(0, len(t_sel) - win_n_ds)]\n",
    "        zoom_labs = [\"Start\", \"Middle\", \"End\"]\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 9))\n",
    "        for i, s in enumerate(starts_ds):\n",
    "            e = min(len(t_sel), s + win_n_ds)\n",
    "            if s >= e:\n",
    "                continue\n",
    "            ax = axes[i]\n",
    "            ax.plot(t_sel[s:e], y_sel[s:e, 0], 'k-', alpha=0.6, linewidth=2, label='Measured')\n",
    "            for name, pred in models_sel.items():\n",
    "                ax.plot(t_sel[s:e], pred[s:e, 0], linestyle=styles_all[name],\n",
    "                        color=colors_all[name], linewidth=1.3, label=name)\n",
    "            ax.set_title(f\"Zoom ({zoom_labs[i]}) — {plot_dataset_name} ({plot_split})\")\n",
    "            ax.set_ylabel(\"Position\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            if i == 0:\n",
    "                ax.legend(fontsize=7, ncol=3)\n",
    "            if i == 2:\n",
    "                ax.set_xlabel(\"Time (s)\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- (C) Residuals (position + velocity) ---\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 7))\n",
    "        for name in model_names_all:\n",
    "            r = residuals_sel.get(name)\n",
    "            if r is None or r.get(\"pos\") is None:\n",
    "                continue\n",
    "            axes[0].plot(t_sel, r[\"pos\"], color=colors_all[name], linewidth=0.9, label=name)\n",
    "        axes[0].axhline(0, color='gray', linewidth=0.8)\n",
    "        axes[0].set_title(f\"Position Residuals ({plot_dataset_name}, {plot_split})\")\n",
    "        axes[0].set_ylabel(\"Residual\")\n",
    "        axes[0].legend(fontsize=7, ncol=3)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        for name in model_names_all:\n",
    "            r = residuals_sel.get(name)\n",
    "            if r is None or r.get(\"vel\") is None:\n",
    "                continue\n",
    "            axes[1].plot(t_sel, r[\"vel\"], color=colors_all[name], linewidth=0.9, label=name)\n",
    "        axes[1].axhline(0, color='gray', linewidth=0.8)\n",
    "        axes[1].set_title(f\"Velocity Residuals ({plot_dataset_name}, {plot_split})\")\n",
    "        axes[1].set_ylabel(\"Residual\")\n",
    "        axes[1].set_xlabel(\"Time (s)\")\n",
    "        axes[1].legend(fontsize=7, ncol=3)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- (D) Raincloud plot (position residuals) ---\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        plot_idx = 0\n",
    "        plotted_names = []\n",
    "        for name in model_names_all:\n",
    "            r = residuals_sel.get(name)\n",
    "            if r is None or r.get(\"pos\") is None:\n",
    "                continue\n",
    "            res = r[\"pos\"]\n",
    "            res = res[np.isfinite(res)]\n",
    "            if len(res) < 5:\n",
    "                continue\n",
    "            kde = gaussian_kde(res)\n",
    "            xs = np.linspace(np.min(res), np.max(res), 200)\n",
    "            ys_kde = kde(xs)\n",
    "            ys_kde = ys_kde / ys_kde.max() * 0.3\n",
    "            ax.fill_between(xs, plot_idx + ys_kde, plot_idx - ys_kde,\n",
    "                            color=colors_all[name], alpha=0.3)\n",
    "            q1, q2, q3 = np.percentile(res, [25, 50, 75])\n",
    "            ax.plot([q1, q3], [plot_idx, plot_idx], color=colors_all[name], linewidth=6)\n",
    "            ax.plot([q2, q2], [plot_idx - 0.1, plot_idx + 0.1], color='k', linewidth=1)\n",
    "            jitter = (np.random.rand(len(res)) - 0.5) * 0.2\n",
    "            ax.scatter(res, plot_idx + jitter, s=2, color=colors_all[name], alpha=0.25)\n",
    "            plotted_names.append(name)\n",
    "            plot_idx += 1\n",
    "\n",
    "        ax.set_yticks(range(len(plotted_names)))\n",
    "        ax.set_yticklabels(plotted_names)\n",
    "        ax.set_xlabel(\"Residual (Position)\")\n",
    "        ax.set_title(f\"Residual Raincloud — Position ({plot_dataset_name}, {plot_split})\")\n",
    "        ax.axvline(0, color='gray', linewidth=0.8, alpha=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- (E) y vs ŷ scatter (position) ---\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        y_min_ds = y_sel[:, 0].min() if len(y_sel) > 0 else 0\n",
    "        y_max_ds = y_sel[:, 0].max() if len(y_sel) > 0 else 1\n",
    "        ax.plot([y_min_ds, y_max_ds], [y_min_ds, y_max_ds], 'k--', linewidth=1, label='Ideal')\n",
    "        for name, pred in models_sel.items():\n",
    "            ax.scatter(y_sel[:, 0], pred[:, 0], s=4, alpha=0.35,\n",
    "                       color=colors_all[name], label=name)\n",
    "        ax.set_xlabel(\"Measured y\")\n",
    "        ax.set_ylabel(\"Predicted y\")\n",
    "        ax.set_title(f\"y vs ŷ — Position ({plot_dataset_name}, {plot_split})\")\n",
    "        ax.legend(fontsize=7, markerscale=3)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nPer-dataset comparison (all models incl. HYCO) complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94788e",
   "metadata": {},
   "source": [
    "## HYCO Hyperparameter Analysis — λ_bb × λ_cons Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, time as _time\n",
    "\n",
    "# =====================================================================\n",
    "# Hyperparameter grid search: lambda_bb x lambda_cons\n",
    "# =====================================================================\n",
    "\n",
    "HP_EPOCHS = 2000\n",
    "HP_LR_PHYS = 0.01\n",
    "HP_LR_BB = 0.01\n",
    "HP_BATCH = 128\n",
    "HP_HIDDEN = 128\n",
    "\n",
    "lambda_bb_vals   = [0.0, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "lambda_cons_vals = [0.0, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def evaluate_hyco_hp(lam_bb, lam_cons):\n",
    "    \"\"\"Train a fresh HYCO with given lambdas; return per-dataset test RMSE.\"\"\"\n",
    "    m = HYCOModel(hidden_dim=HP_HIDDEN)\n",
    "    m, _ = train_hyco(\n",
    "        m,\n",
    "        epochs=HP_EPOCHS,\n",
    "        lr_phys=HP_LR_PHYS,\n",
    "        lr_bb=HP_LR_BB,\n",
    "        lambda_bb=lam_bb,\n",
    "        lambda_cons=lam_cons,\n",
    "        batch_size=HP_BATCH,\n",
    "        log_every=HP_EPOCHS + 1,   # silent\n",
    "    )\n",
    "    m.eval()\n",
    "\n",
    "    per_ds = {}\n",
    "    for ds_name in all_datasets:\n",
    "        base = eval_store[ds_name]\n",
    "        t_ds = base[\"t\"]\n",
    "        y_sim_ds = base[\"y_sim\"]\n",
    "\n",
    "        t_ds_t = torch.tensor(t_ds, dtype=torch.float32).to(device)\n",
    "        u_ds_t = torch.tensor(datasets_cache[ds_name][\"u\"],\n",
    "                              dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "        y_ds_t = torch.tensor(y_sim_ds, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x0_ds = y_ds_t[0].unsqueeze(0)\n",
    "\n",
    "            m.phys.u_series = u_ds_t\n",
    "            m.phys.t_series = t_ds_t\n",
    "            m.phys.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "            p_phys = odeint(m.phys, x0_ds, t_ds_t, method=\"rk4\").squeeze(1).cpu().numpy()\n",
    "\n",
    "            m.bb.u_series = u_ds_t\n",
    "            m.bb.t_series = t_ds_t\n",
    "            m.bb.batch_start_times = torch.zeros(1, 1).to(device)\n",
    "            p_bb = odeint(m.bb, x0_ds, t_ds_t, method=\"rk4\").squeeze(1).cpu().numpy()\n",
    "\n",
    "        p_ens = 0.5 * (p_phys + p_bb)\n",
    "\n",
    "        # test-split RMSE for each sub-model\n",
    "        ds_metrics = {}\n",
    "        for sub_name, sub_pred in [(\"HYCO-Phys\", p_phys),\n",
    "                                    (\"HYCO-BB\", p_bb),\n",
    "                                    (\"HYCO-Ens\", p_ens)]:\n",
    "            idx = base[\"test_idx\"]\n",
    "            if idx is None or len(idx) < 2:\n",
    "                ds_metrics[sub_name] = np.nan\n",
    "                continue\n",
    "            res = y_sim_ds[idx, 0] - sub_pred[idx, 0]\n",
    "            ds_metrics[sub_name] = np.sqrt(np.mean(res**2))\n",
    "\n",
    "        per_ds[ds_name] = ds_metrics\n",
    "\n",
    "    return per_ds\n",
    "\n",
    "\n",
    "# --- Run grid search ---\n",
    "print(f\"Grid: {len(lambda_bb_vals)} x {len(lambda_cons_vals)} = \"\n",
    "      f\"{len(lambda_bb_vals)*len(lambda_cons_vals)} combos, \"\n",
    "      f\"{HP_EPOCHS} epochs each\\n\")\n",
    "\n",
    "results = []\n",
    "t0 = _time.time()\n",
    "\n",
    "for i, (lam_bb, lam_cons) in enumerate(\n",
    "        itertools.product(lambda_bb_vals, lambda_cons_vals)):\n",
    "    print(f\"[{i+1:>3d}/{len(lambda_bb_vals)*len(lambda_cons_vals)}] \"\n",
    "          f\"λ_bb={lam_bb:.1f}, λ_cons={lam_cons:.1f} ... \", end=\"\", flush=True)\n",
    "    ts = _time.time()\n",
    "    per_ds = evaluate_hyco_hp(lam_bb, lam_cons)\n",
    "    elapsed = _time.time() - ts\n",
    "\n",
    "    # Average across sub-models => pick Ens for ranking\n",
    "    avg_ens_rmse = np.nanmean([per_ds[d][\"HYCO-Ens\"] for d in all_datasets])\n",
    "    avg_phys_rmse = np.nanmean([per_ds[d][\"HYCO-Phys\"] for d in all_datasets])\n",
    "    avg_bb_rmse = np.nanmean([per_ds[d][\"HYCO-BB\"] for d in all_datasets])\n",
    "\n",
    "    # Scenario 2: exclude rampa_positiva & rampa_negativa\n",
    "    excl = {\"rampa_positiva\", \"rampa_negativa\"}\n",
    "    ds_filtered = [d for d in all_datasets if d not in excl]\n",
    "    avg_ens_rmse_no_ramp = np.nanmean([per_ds[d][\"HYCO-Ens\"] for d in ds_filtered])\n",
    "\n",
    "    results.append({\n",
    "        \"lam_bb\": lam_bb,\n",
    "        \"lam_cons\": lam_cons,\n",
    "        \"avg_ens_rmse\": avg_ens_rmse,\n",
    "        \"avg_phys_rmse\": avg_phys_rmse,\n",
    "        \"avg_bb_rmse\": avg_bb_rmse,\n",
    "        \"avg_ens_rmse_no_ramp\": avg_ens_rmse_no_ramp,\n",
    "        \"per_ds\": per_ds,\n",
    "    })\n",
    "    print(f\"RMSE(Ens)={avg_ens_rmse:.5f}  (no ramp={avg_ens_rmse_no_ramp:.5f})  [{elapsed:.1f}s]\")\n",
    "\n",
    "total_time = _time.time() - t0\n",
    "print(f\"\\nGrid search finished in {total_time/60:.1f} min.\\n\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Scenario 1 — All datasets\n",
    "# =====================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"  SCENARIO 1: All datasets\")\n",
    "print(\"=\" * 80)\n",
    "sorted_all = sorted(results, key=lambda r: r[\"avg_ens_rmse\"])\n",
    "print(f\"\\n{'Rank':<5} {'λ_bb':>6} {'λ_cons':>7} {'RMSE Ens':>10} {'RMSE Phys':>11} {'RMSE BB':>9}\")\n",
    "print(\"-\" * 55)\n",
    "for rank, r in enumerate(sorted_all[:15], 1):\n",
    "    marker = \" <-- best\" if rank == 1 else \"\"\n",
    "    print(f\"{rank:<5} {r['lam_bb']:6.1f} {r['lam_cons']:7.1f} \"\n",
    "          f\"{r['avg_ens_rmse']:10.5f} {r['avg_phys_rmse']:11.5f} {r['avg_bb_rmse']:9.5f}{marker}\")\n",
    "\n",
    "best_all = sorted_all[0]\n",
    "print(f\"\\n★ Best (all datasets): λ_bb={best_all['lam_bb']:.1f}, \"\n",
    "      f\"λ_cons={best_all['lam_cons']:.1f}  ⇒  RMSE={best_all['avg_ens_rmse']:.5f}\")\n",
    "\n",
    "# Per-dataset breakdown for best\n",
    "print(f\"\\n  Per-dataset breakdown (best combo):\")\n",
    "print(f\"  {'Dataset':<25} {'HYCO-Phys':>11} {'HYCO-BB':>11} {'HYCO-Ens':>11}\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "for ds_name in all_datasets:\n",
    "    m = best_all[\"per_ds\"][ds_name]\n",
    "    print(f\"  {ds_name:<25} {m['HYCO-Phys']:11.5f} {m['HYCO-BB']:11.5f} {m['HYCO-Ens']:11.5f}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Scenario 2 — Without rampa_positiva & rampa_negativa\n",
    "# =====================================================================\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"  SCENARIO 2: Excluding rampa_positiva & rampa_negativa\")\n",
    "print(\"=\" * 80)\n",
    "sorted_no_ramp = sorted(results, key=lambda r: r[\"avg_ens_rmse_no_ramp\"])\n",
    "print(f\"\\n{'Rank':<5} {'λ_bb':>6} {'λ_cons':>7} {'RMSE Ens':>10}\")\n",
    "print(\"-\" * 32)\n",
    "for rank, r in enumerate(sorted_no_ramp[:15], 1):\n",
    "    marker = \" <-- best\" if rank == 1 else \"\"\n",
    "    print(f\"{rank:<5} {r['lam_bb']:6.1f} {r['lam_cons']:7.1f} \"\n",
    "          f\"{r['avg_ens_rmse_no_ramp']:10.5f}{marker}\")\n",
    "\n",
    "best_nr = sorted_no_ramp[0]\n",
    "print(f\"\\n★ Best (excl. ramps): λ_bb={best_nr['lam_bb']:.1f}, \"\n",
    "      f\"λ_cons={best_nr['lam_cons']:.1f}  ⇒  RMSE={best_nr['avg_ens_rmse_no_ramp']:.5f}\")\n",
    "\n",
    "# Per-dataset breakdown\n",
    "ds_filt = [d for d in all_datasets if d not in excl]\n",
    "print(f\"\\n  Per-dataset breakdown (best combo, excl. ramps):\")\n",
    "print(f\"  {'Dataset':<25} {'HYCO-Phys':>11} {'HYCO-BB':>11} {'HYCO-Ens':>11}\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "for ds_name in ds_filt:\n",
    "    m = best_nr[\"per_ds\"][ds_name]\n",
    "    print(f\"  {ds_name:<25} {m['HYCO-Phys']:11.5f} {m['HYCO-BB']:11.5f} {m['HYCO-Ens']:11.5f}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Heatmaps\n",
    "# =====================================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for ax, key, title in [\n",
    "    (axes[0], \"avg_ens_rmse\",         \"RMSE (Ens) — All datasets\"),\n",
    "    (axes[1], \"avg_ens_rmse_no_ramp\", \"RMSE (Ens) — Excl. ramps\"),\n",
    "]:\n",
    "    grid = np.full((len(lambda_cons_vals), len(lambda_bb_vals)), np.nan)\n",
    "    for r in results:\n",
    "        i = lambda_cons_vals.index(r[\"lam_cons\"])\n",
    "        j = lambda_bb_vals.index(r[\"lam_bb\"])\n",
    "        grid[i, j] = r[key]\n",
    "\n",
    "    im = ax.imshow(grid, origin=\"lower\", aspect=\"auto\", cmap=\"viridis_r\")\n",
    "    ax.set_xticks(range(len(lambda_bb_vals)))\n",
    "    ax.set_xticklabels([f\"{v:.1f}\" for v in lambda_bb_vals])\n",
    "    ax.set_yticks(range(len(lambda_cons_vals)))\n",
    "    ax.set_yticklabels([f\"{v:.1f}\" for v in lambda_cons_vals])\n",
    "    ax.set_xlabel(\"λ_bb\")\n",
    "    ax.set_ylabel(\"λ_cons\")\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im, ax=ax, shrink=0.8, label=\"RMSE\")\n",
    "\n",
    "    # annotate values\n",
    "    for ii in range(grid.shape[0]):\n",
    "        for jj in range(grid.shape[1]):\n",
    "            val = grid[ii, jj]\n",
    "            if np.isfinite(val):\n",
    "                ax.text(jj, ii, f\"{val:.4f}\", ha=\"center\", va=\"center\",\n",
    "                        fontsize=7, color=\"white\" if val > np.nanmedian(grid) else \"black\")\n",
    "\n",
    "fig.suptitle(\"HYCO Hyperparameter Grid Search\", fontsize=14, fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Bar chart: top-5 combos for each scenario\n",
    "# =====================================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, sorted_list, scenario in [\n",
    "    (axes[0], sorted_all,     \"All datasets\"),\n",
    "    (axes[1], sorted_no_ramp, \"Excl. ramps\"),\n",
    "]:\n",
    "    top5 = sorted_list[:5]\n",
    "    labels = [f\"bb={r['lam_bb']:.1f}\\ncons={r['lam_cons']:.1f}\" for r in top5]\n",
    "    rmses  = [r[\"avg_ens_rmse\"] if scenario == \"All datasets\"\n",
    "              else r[\"avg_ens_rmse_no_ramp\"] for r in top5]\n",
    "    bars = ax.bar(labels, rmses, color=[\"gold\", \"silver\", \"#cd7f32\", \"skyblue\", \"lightgray\"])\n",
    "    ax.set_ylabel(\"Avg Test RMSE (Ens)\")\n",
    "    ax.set_title(f\"Top-5 HP combos — {scenario}\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "    for b, v in zip(bars, rmses):\n",
    "        ax.text(b.get_x() + b.get_width()/2, b.get_height(),\n",
    "                f\"{v:.5f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHyperparameter analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
